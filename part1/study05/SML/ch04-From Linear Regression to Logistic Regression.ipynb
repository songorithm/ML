{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 4. From Linear Regression to Logistic Regression\n",
    "=========================================================\n",
    "\n",
    "#### 발표자: 김덕태 (2015-08-31)\n",
    "\n",
    "#### generalized linear model\n",
    "- a flexible framework that requires fewer assumptions than ordinary linear regression\n",
    "- special cases of generalized linear model\n",
    "  - simple linear regression\n",
    "  - multiple linear regression\n",
    "  - polynomial regression\n",
    "  - logistic regression\n",
    "\n",
    "#### logistic regression\n",
    "- used for classification tasks\n",
    "- goal in classification tasks\n",
    "  - find a function that maps an observation to its associated class or label\n",
    "\n",
    "#### A learning algorithm\n",
    "- use pairs of feature vectors and their corresponding labels to induce the values of the mapping function's parameters\n",
    "- produce the best classifier\n",
    "- measured by a particular performance metric\n",
    "\n",
    "#### binary classification\n",
    "- the classifier must assign instances to one of the two classes\n",
    "\n",
    "#### multiclass classification\n",
    "- the classifier must assign one of several labels to each instance\n",
    "\n",
    "#### multilabel classification\n",
    "- the classifier must assign a subset of the labels to each instance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Binary classification with logistic regression\n",
    "\n",
    "#### normal distribution(also known as the Gaussian distribution or bell curve)\n",
    "- ordinary linear regression assumes that the response variable is normally distributed\n",
    "- Normally distributed data is symmetrical\n",
    "  - half of the values are greater than the mean and the other half of the values are less than the mean.\n",
    "- The mean, median, and mode of normally distributed data are also equal\n",
    "- Many natural phenomena approximately follow normal distributions.\n",
    "  - Ex) the height of people\n",
    "\n",
    "\n",
    "#### Bernoulli distribution\n",
    "- In some problems the response variable is not normally distributed.\n",
    "  - Ex) a coin toss can result in two outcomes: heads or tails\n",
    "- The probability distribution of a random variable that can take the positive case with probability P or the negative case with probability 1-P.\n",
    "- If the response variable represents a probability, it must be constrained to the range {0,1}\n",
    "- Linear regression assumes that a constant change in the value of an explanatory variable results in a constant change in the value of the response variable, an assumption that does not hold if the value of the response variable represents a probability\n",
    "\n",
    "- Generalized linear models remove this assumption by relating a linear combination of the explanatory variables to the response variable using a link function\n",
    "- ordinary linear regression is a special case of the generalized linear model that relates a linear combination of the explanatory variables to a normally distributed response variable using the identity link function\n",
    "- We can use a different link function to relate a linear combination of the explanatory variables to the response variable that is not normally distributed.\n",
    "\n",
    "#### logistic regression\n",
    "- response variable describes the probability that the outcome is the positive case\n",
    "- If the response variable is equal to or exceeds a discrimination threshold, the positive class is predicted\n",
    "- otherwise, the negative class is predicted\n",
    "\n",
    "#### logistic function\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)\n",
    "\n",
    "- The response variable is modeled as a function of a linear combination of the explanatory variables using the logistic function\n",
    "- logistic function\n",
    "$$\\sigma(t) = \\frac{e^t}{e^t + 1} = {1 \\over 1 + e^{-t}}$$\n",
    "- another form of logistic function\n",
    "  - t: a linear combination of explanatory variables ($\\beta_0 + \\beta_1 x$)\n",
    "$$F(x) = {1 \\over 1 + e^{-(\\beta_0 + \\beta_1 x)}}$$\n",
    "  \n",
    "#### logit function\n",
    "- inverse of logistic function\n",
    "- formula\n",
    "$$ g(x) =  ln {x \\over 1-x}$$\n",
    "$$ g(F(x)) =  ln {F(x) \\over 1-F(x)} = \\beta_0 + \\beta_1 x$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam filtering\n",
    "- modern version of the canonical binary classification problem\n",
    "- classify spam and ham SMS messages\n",
    "- some predictions using scikit-learn's LogisticRegression class\n",
    "\n",
    "#### data set\n",
    "- SMS Spam Classification Data Set from the UCI Machine Learning Repository\n",
    "  - http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### explore the data set and calculate some basic summary statistics using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/SMSSpamCollection', delimiter='\\t', header=None)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- A binary label and a text message comprise each row\n",
    "- 5,574 ham SMS messages\n",
    "  - 4,827 real ham \n",
    "  - 747 spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Preparation of training and test data \n",
    "- load the .csv file using pandas\n",
    "- split the data set into training and test sets\n",
    "- train_test_split()\n",
    "  - assigns 75 percent of the samples to the training set and allocates the remaining 25 percent of the samples to the test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "\n",
    "df = pd.read_csv('data/SMSSpamCollection', delimiter='\\t', header=None)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1], df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract TF-IDF features\n",
    "- TF-IDF: the product of its term frequency and inverse document frequency\n",
    "- TfidfVectorizer combines CountVectorizer and TfidfTransformer\n",
    "- fit it with the training messages, and transform both the training and test messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use LogisticRegression class\n",
    "- create an instance of LogisticRegression and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ham. Message: Hi juan. Im coming home on fri hey. Of course i expect a welcome party and lots of presents. Ill phone u when i get back. Loads of love nicky x x x x x x x x x\n",
      "Prediction: ham. Message: Jason says it's cool if we pick some up from his place in like an hour\n",
      "Prediction: ham. Message: Can not use foreign stamps in this country.\n",
      "Prediction: ham. Message: Night has ended for another day, morning has come in a special way. May you smile like the sunny rays and leaves your worries at the blue blue bay. Gud mrng\n",
      "Prediction: ham. Message: Ma head dey swell oh. Thanks for making my day\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "for i, prediction in enumerate(predictions[:5]):\n",
    "    print('Prediction: %s. Message: %s' % (prediction, X_test_raw[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification performance metrics\n",
    "\n",
    "#### metrics\n",
    "- accuracy\n",
    "- precision, recall\n",
    "- F1 measure\n",
    "- ROC AUC score\n",
    "\n",
    "#### basis for metrics\n",
    "- concepts of true positives, true negatives, false positives, and false negatives\n",
    "  - Positive and negative refer to the predicted classes\n",
    "  - True and false denote whether the predicted class is the same as the true class.\n",
    "- Ex)\n",
    "  - a true negative prediction: the classifier correctly predicts that a message is ham.\n",
    "  - a false positive prediction: A prediction that a ham message is spam\n",
    "  - a false negative prediction: a spam message incorrectly classified as ham\n",
    "\n",
    "#### A confusion matrix(or contingency table)\n",
    "- visualize true and false positives and negative\n",
    "\n",
    "|         | Negative | Positive\n",
    "|---------|:--------:|:-------:\n",
    "|Negative | TN       | FP     \n",
    "|Positive | FN       | TP     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 3]]\n"
     ]
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAQIAAADyCAYAAACmqsv9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAGENJREFUeJzt3Xm0ZGV97vHvQ9PMIJMhAo19g6CiDE2SZhJpotcgMRAj\n",
       "CWEwS8VA5BK9gknUGKS9mizWylWMIjIHJYIaNIhMmhuOjNLMSBABUWSGZjAMDT3w3D/2PlBdnKra\n",
       "p07X2btOPZ+19uratd969++cPvtX7/vu4ZVtImK0rVZ3ABFRvySCiEgiiIgkgoggiSAiSCKICJII\n",
       "IoaSpFmSbpJ0QYft/yzpLkm3SJrXq74kgojh9BHgduAVFwJJ2hd4ne1tgMOBk3pVlkQQMWQkbQns\n",
       "C5wGaIIi+wFnAdi+FthQ0mbd6kwiiBg+XwD+Gnixw/YtgPta1u8HtuxWYRJBDSStLekCSU9J+uYU\n",
       "6jlE0qWrMra6SNpT0h11x9F0kt4FPGr7JiZuDbxUtG29670ESQRdSDpY0vWSnpb0oKSLJO2xCqo+\n",
       "APgNYGPbB/Zbie1/tf37qyCegZL0oqTf6lbG9hW23zBdMdVJkieztH18d2A/Sb8AzgF+T9LX2so8\n",
       "AMxpWd+yfK+j1af6Q81Uko4G/hY4ArgUWArsQ9H/umqK1b8WuNN2p6bdTNTx20vS6raXT2cwdfts\n",
       "xXKfalu3/UngkwCS9gI+ZvvP24p9DzgKOFfSrsBTth/ptp+0CCYg6VXAQuBI2/9ue4ntFbYvtP23\n",
       "ZZk1JZ0g6YFy+YKkNcptCyTdL+loSY+UrYn3ldsWAn8PHFi2ND4g6ThJX2/Z/9zyW3S1cv19kn4u\n",
       "6b8l3SPp4Jb3r2j53O6Sriu7HIsk7daybUzSZyRdWdZzqaRNOvz84/H/taRHy/j/SNK+ku6U9Lik\n",
       "j7eUny/pGklPlmW/JGl2ue3ystgt5c/7Jy31/42kh4DTy/fuKz+zdbmPeeX65pIek/TWKf3HNsjs\n",
       "iksFBpB0hKQjAGxfBNwj6W7gZODIXpUkEUxsN2At4LtdyvwdMB/YsVzms3IC3wzYANgcOAw4UdKr\n",
       "bH8a+AfgXNvr2z6DLv03SesCXwT2sb1BGdvNE5TbGLgQOAHYGPg8cKGkjVqKHQS8j6JbsgbwsS4/\n",
       "32bAmsBrgGMpRqgPAeYBewLHSnptWXY5xemsTcr43kb5x2d7/ODdofx5v91S/0bAVhStrpfY/jlF\n",
       "a+xsSWsDZwJn2r6cGWL1iks3tn9ke7/y9cm2T27ZdpTt19ne0faNveJJIpjYJsDiHk33g4HP2F5s\n",
       "ezFFC+K9LduXldtX2L4YeAZ4fblNrNxU7jboA8Xo8PaS1rb9iO3bJyjzB8DPynGDF22fC9xB0ZWB\n",
       "Itmcaftu288D3wJ26rLPZcDnbK8AvkmRXE6w/Wy5/9vHP2/7RtuLyv3eC5wC7FXhZ/q07WVlPCux\n",
       "fRpwN7CIImn8XY/6hsraFZfpkkQwsceBTceb5h1sDtzbsv6r8r2X6mhLJM8B6002ENvPAgcCfwk8\n",
       "KOn7kl4/QdHNyxha3dsW08Mtr5f0iOdxv/zUmiXlv639zCXAugCSti3jekjSr4HPUSTTbh6zvbRH\n",
       "mdOANwFfsr2sR9mhsgq7BqtEEsHErgFeAN7dpcyDwNyW9a3K9/rxDLBOy/pvtm60/QPb7yjfvwM4\n",
       "dYI6HqAYhGz1WnqMFq8iJ1G0EF5n+1UU3969/ra6ns6StB5FN+c0YGFbF2forYquwaqURDAB27+m\n",
       "6BefKGl/SetImi3pnZKOL4udA3xK0qaSNi3Lf71TnT3cDLxV0pxyoPIT4xsk/UYZw7oUzfVngRUT\n",
       "1HExsK2kgyStLulA4A3A91vK9OqC9Gs94GngOUlvAD7Utv0RYOtJ1vlFYJHtwynGPr465SgbJC2C\n",
       "IWH788DRFAOAj1I0u4/k5QHEzwLXA7eWy/WsfFao2zeeW7fb/g+KfvitwHXABS3bVwM+SvHN/jjF\n",
       "QN2H2uux/TjwLuAYYDHFQOC7bD/RISbTO8Zu660+RjFm8t8U4wPntpU/DjirPKtwQJd9j4+A7w+8\n",
       "g5d/zqOBnSUd1CWGodK0FoHy8NJqJO1D0VSdBZxm+/geH4lJknQGxaDno7a3rzueQZHk8yqWfQ9g\n",
       "e1AtuZekRVCBpFnAlykuKNoOOEjSG+uNakY6k+J3POM1rWuQKwurmQ/cbfuXAJLOBfYHflpnUDON\n",
       "7Sskza07jukwnacGq0giqGaiu7l2qSmWmAGaduA1LZ6mykBKrFLT2eyvIomgmva7ueZQtAoi+tK0\n",
       "A69p8TTV9cA2Zf/1QYor/WbMqayYfk1rEeSsQQXlLbJHUdyOfDvwTdsZKFzFJJ0DXE1xYdR9kt5f\n",
       "d0yDkusIIkacpAnvGpvIdkzPdQTpGkTUIKcPI6JxYwRJBBE1aNqB17R4IkbC7KpH3jQ9ybHWRKBX\n",
       "PqE1YmhNZlBv9SSClX267gAmaQxYUHMMk7Uwv+VpsHBSpWfPGlAYfao9EUSMosotgmnSsHAiRsPs\n",
       "Nfv7nKS1gB9RPGF6DeB825+YoNwCiqnRZlM8iHdBt3qTCCZpbt0BjIS5dQcweH0eebafl7S37eck\n",
       "rQ5cKekttq8cLyNpQ+BE4Pdt318+Sm8Q4YyuuXUHMBLm1h3A4E3hyLP9XPlyDYonZj3RVuRg4Dzb\n",
       "95flF/eqM/caRNRhCjcbSFpN0s0UD4W9bIJ5LrYBNpZ0mYq5O9/7ylpeGU5ETLcOZw3GnoOxJRNv\n",
       "G1fOl7FT+cTrSyUtsD3WUmQ2sDPFjFPrANdI+rHtuzrVmUQQUYcOR96CDYpl3ML2Rn8L27+WdCHw\n",
       "OxTnXMfdRzFAuARYUs4/uSPQMRGkaxBRhzUrLm3KeTQ2LF+vDfxP4Ka2YucDb5E0S9I6FI/V63rD\n",
       "Y1oEEXXo/8h7DcUcEatRfJF/3fb/a5kJ+WTbd0i6hGKejBeBUzvMl7kKwomI/vV/+vAnFP3/9vdP\n",
       "blv/J+CfBhxORExJLjGOiKYdeQ0LJ2JENOzIa1g4ESOiYUdew8KJGBF93nQ0KEkEEXVo2JHXsHAi\n",
       "RkTOGkRE0468hoUTMSIaduQ1LJyIEZGuQUQ07chrWDgRI2KtugNYWRJBRB3SNYiIph15DQsnYkQ0\n",
       "7MhrWDgRIyJdg4ho2pHXsHAiRkTDjryGhRMxInL3YUQ07chrWDgRI6JhR17mNYiow6yKSxtJa0m6\n",
       "VtLNkm6X9I8TlDlE0i2SbpV0laQdeoXTsLwUMSIGOBsycA/w1nImpH2AU4BdBxBOREzJAGdDtn1N\n",
       "y+q1wJa96kzXIKIOfXYNoNJsyK0OAy7qFU5aBBF16HD34djtxdJNhdmQAZC0N/ABYI9e4SQRRNSh\n",
       "02zIOxTLuIXnda6iy2zIlAOEpwL72H6yVzjpGkTUof+zBj1nQ5a0FfAd4FDbd1cJZ6AtgnLE8gSK\n",
       "H+k028cPcn8RQ2OAsyEDxwIbASdJAlhme/5gwulB0izgy8DbgQeA6yR9z/ZPB7XPiKExwNmQbX8Q\n",
       "+OBk6h1k12A+cLftX9peBpwL7D/A/UUMjymcNRiEQXYNtgDua1m/H9hlgPuLGB4j9MxCD7DuiOE2\n",
       "Qg8meQCY07I+h6JVsJKxltdzyyWi+X5ZLn1q2In7QYZzPbCNpLnAg8CBwEHthRYMMICIwZnLyl9b\n",
       "P5rcx0clEdheLuko4FKKhtDpOWMQURqVRABg+2Lg4kHuI2IojdAYQUR00rAjr2HhRIyIPLMwIpp2\n",
       "5DUsnIgR0bAjr2HhRIyIhh15DQsnYjQ4Zw0iYkXDjryGhRMxGpIIIoIX1lyjYsmlA41jXBJBRA1W\n",
       "zGrWIEESQUQNVjTsGuMkgogaLE8iiIgVDTv08jjziBqsYFalpZ2kOZIuk/Rfkm6T9OEJymwq6ZJy\n",
       "otTbJL2vVzzNSksRI2IKYwTLgI/avlnSesANkn7Y9qyPo4CbbH9C0qbAzySdbXt5p0qTCCJq8AJV\n",
       "Tx+uzPbDwMPl62ck/RTYHGhNBA8B4/MlbQA83i0JQBJBRC1WxRhB+RjAeRQzHrc6FfhPSQ8C6wN/\n",
       "2quuJIKIGkz19GHZLfg34CO2n2nb/EngZtsLJG0N/FDSjraf7lRfx0Qg6Utd4rDtVwxSREQ1nRLB\n",
       "9WPPcv3Yc10/K2k2cB5wtu1/n6DI7sDnAGz/XNIvgNdTPFB4Qt1aBDfw8twEKv91+TpzFkRMQafr\n",
       "CHZasAE7LdjgpfVTFi5eabuKyQxPB263fUKH6u+gmGrwKkmbUSSBe7rF0zER2P6XtgDWtf1st8oi\n",
       "opopjBHsARwK3CppfBbkTwJbwUtzIP4DcKakWyguEfgb2090q7RnNJJ2B06jGHSYI2kn4HDbR/b7\n",
       "k0SMun7HCGxfSY/rf2wvBv5wMvVWSUsnAPsA55c7uVnSXpPZSUSsbGmfpw8HpVL7xPavynnWx3U9\n",
       "JxkR3Q3jvQa/krQHgKQ1gA+z8sULETFJTbvXoEo0HwK+SDHN+QPAD4D/NcigIma6obsN2fZjwMHT\n",
       "EEvEyGhaIuh596GkrSVdIGmxpMcknS/pt6YjuIiZajmzKi3TpUrX4BvAl4E/LtcPBM4BdhlUUBEz\n",
       "3dKGzXlW5XkEa9v+uu1l5XI2sNagA4uYyfp9HsGgdLvXYGOKy4kvlvQJilYAFC2CTHUeMQXDdPrw\n",
       "Rla+p+Dw8t/xew0+PqigIma6oTl9aHvuNMYRMVKadtagUlqS9GZgO1rGBmx/bVBBRcx0Q5cIJB0H\n",
       "7AW8CbgQeCdwJZBEENGnoUsEwAHAjsCNtt9f3t/8r4MNK2Jme6Fhpw+rJIIltldIWi7pVcCjwJwB\n",
       "xxUxow1ji+A6SRtRPBDxeuBZ4OqBRhUxww1dImh5AMlXJV0KbGD7lsGGFTGzDc11BJJ+mw7PJpS0\n",
       "s+0bBxZVxAw3NNcRAP+X7g8p3XtVBLDwtjwHddC8kXoXiinRFpMrPzRdA9sLpjGOiJEyNIkgIgan\n",
       "3ynPBiWzIUfUYAWrV1raVZkNuaXs75an/f+4U5lxaRFE1GDAsyEjaRZwPHAJL09Q1FGVJxStJum9\n",
       "ko4t17eSNL+vHyEigP6fR2D7Yds3l6+foXiQ8OYT7OKvKOZGfKxKPFW6Bl8BduPl5xY+U74XEX1a\n",
       "FY8q6zQbsqQtgP2Bk8q3ep6aq9I12MX2vPHplWw/UU7CGBF9mup1BD1mQz4B+Lhtl3Ml9uwaVIlm\n",
       "adnfGA/g1cCLk4g5Itp0GiN4aOxOHh67s+tnK8yG/NvAueWkRJsC75S0zPb3OtZpd281SDoU+NOy\n",
       "8rMo7kb8lO1vdf1gBZJMLigauFxQNHjaAmxX+kVL8sE+vVK939BhK9VbfsOfBTxu+6MV9nUmcIHt\n",
       "73QrV+Veg7Ml3QC8rXxr//YRyoiYnCnca1BlNuRJq/Jgkq0o7ji8oHzLkray/at+dhgR/Y8RVJkN\n",
       "ua38+6uUqxLNRbw86rgW8D+An1E8sSgi+jB0lxjbfnPruqSdydyHEVMydImgne0bJWWWo4gpGJrn\n",
       "EYyTdEzL6mrAzhSzIkdEn4bpeQTj1mt5vRz4PsU5zIjo09KG3X3YNRGUFxJtYPuYbuUiYnKGpmsg\n",
       "aXXbyyXtIUnudeVRRFQ2TF2DRRTjATcD50v6NvBcuc29rlSKiM6G6azB+GWNawGPA7/Xtj2JIKJP\n",
       "w5QIXi3paOAn0xVMxKgYpkQwC1h/ugKJGCXDNOXZw7YXTlskESNkmFoEETEgw5QI3j5tUUSMmKG5\n",
       "jsD249MZSMQoGabrCCJiQIapaxARA5JEEBG8sHSIbjqKiMFYsbxZh16zookYESuWp2sQMfKalggy\n",
       "G3JEDZYvm1VpaVd1NmRJ/yzpLkm3SJrXK560CCJq8OKKvg+9nrMhS9oXeJ3tbcrni54E7Nqt0iSC\n",
       "iDr02TWw/TDwcPn6GUnjsyG3Tjq0H8VsSNi+VtKGkjaz/UinepMIIurw/NQPvU6zIQNbAPe1rN8P\n",
       "bAkkEUQ0yvIO7y8ag+vGen68x2zI8MoZkLs+ajCJIKIOnRLBzguKZdxXXvkkgAqzIT8AzGlZ35Ie\n",
       "UxDkrEFEHZZXXNqUsyGfDtxu+4QOtX8P+POy/K7AU93GB2DALQJJZwB/ADxqe/tB7itiqCzr+5M9\n",
       "Z0O2fZGkfSXdTTGBcc+JUDXIp5RL2hN4BvjaRIlAkrktT0kfNG/U3l2MVU1bgO1Kv2hJ5qqKf/d7\n",
       "qHK9UzHQFoHtK8qRzYho1WmMoCYZLIyow/N1B7CyJIKIOqRF0ObE415+/bsLYP6CmgKJqG7sahi7\n",
       "ZgoVNCwRDHSwEF66+umCDBbWJ4OFgzfpwcLzKv7dv2d6BgsHeh2BpHOAq4FtJd0nqedpjIiRsKzi\n",
       "Mk0GfdbgoEHWHzG0VtQdwMrqHyOIGEUNGyNIIoioQ04fRkRaBBGRRBARJBFEBNN6arCKJIKIOuT0\n",
       "YUTkrEFEZIwgIsgYQUSQMYKIIF2DiCCJICJo3BhB5jWIqMMLFZc2ks6Q9Iikn3SqWtICSTeVsyWP\n",
       "VQkniSCiDn1OcAKcCezTqVpJGwInAn9o+83AAVXCSdcgog59dg0qTBFwMHCe7fvL8our1JsWQUQd\n",
       "VlRcJm8bYGNJl0m6XtJ7q3woLYKIOnQ6a7B4DB4fm0rNs4GdgbcB6wDXSPqx7bu6fSiJIKIOnRLB\n",
       "hguKZdydr5wNuYf7gMW2lwBLJF0O7Ah0TQTpGkTUYXBPMT4feIukWZLWAXYBbu/1obQIIuowwanB\n",
       "KsopAvYCNpV0H/Bpiu7A+EzId0i6BLgVeBE41XbPRDDwCU667jwTnEyLTHAyeJOe4GS3in/318yA\n",
       "2ZAjooOGXVmYRBBRh9x9GBG56SgikggigowRRAR9nz4clCSCiDqkaxAR6RpERE4fRgTpGkQESQQR\n",
       "QcYIIoLGtQjyPILJWjRWdwQz3tjVdUcwepIIJuu6sbojmPHGrqk7gtGTRBARGSOIqEezRgvrf0JR\n",
       "xAwxqScU8VzFWteZ+U8omo4fMKKZmtUiSNcgohZL6g5gJUkEEbVoVosgZw0iatHfLKi9ZkOWdIik\n",
       "WyTdKukqSTtUiSaJIKIWfc9w0nU2ZOAe4K22dwD+D3BKlWiSCAZA0opyfvqfSPqWpLWnUNe/SHpP\n",
       "+fpUSW/sUnYvSbv1sY9fStq46vttZZ6Z5L6Ok3TMZGOcefprEdi+AniyU622r7H963L1WmDLKtEk\n",
       "EQzGc7bn2d4eWAr8ZetGSZMZm3G5YPsvbP+0S9m9gd0nG+x4/ZN4f7JlplJ+hhrcnGctDgMuqlIw\n",
       "g4WDdwWwg6S9gM8CTwCvl7QdcDzF9FVrAifaPkWSgC8Bb6eY0HLpeEWSxoBjbN8gaR/gc8As4DHg\n",
       "g8ARwApJhwJHAXcCJwFblVX8b9tXS9oEOAfYHLgG6HkaV9J3gTnAWsAXbZ/asu3zwDuAh4E/s71Y\n",
       "0tbAl4FXU5w0/wvbP5vUb25G63TW4AbgxinXLmlv4APAHlXKJxEMUPnNvy8vZ+V5wJts3yvpcOAp\n",
       "2/MlrQlcKekHFFNabwu8EfhNigksTy8/b8CSXk3R99uzrGtD209J+irwtO3Pl/v/BvAF21dJ2gq4\n",
       "BNiOYr68y21/VtK+FN8cvXzA9pNlN2eRpH+z/SSwLnCd7aMl/X1Z91+V8R1h+25JuwBfoZiqO4DO\n",
       "tx/uWC7jTu9QrrNygPBUYJ/y/6inJILBWFvSTeXry4EzKDLzItv3lu+/A9he0gHl+gbANsCewDdc\n",
       "XPL5kKT/bKtbwK4UB/K9ALafats+7u3AG4tGBgDrS1q33Me7y89eJKnKH8tHJP1R+XpOGesiiok2\n",
       "v1m+fzbwnXIfuwPfbtn3GhX2MUIGc/qwTPjfAQ61fXfVzyURDMYS2/Na3ygPiGfbyh1l+4dt5fal\n",
       "d1O9aj9bwC62l670ZhFL5as6JS2g+Dbf1fbzki6j6CJMtD9TjD092f47iFb9PZCg12zIwLHARsBJ\n",
       "5f/zMtvze9WbwcL6XAocOT5wKGnbcj77y4EDJa0m6TUUA4CtDPwYeKukueVnx0f2nwbWbyn7A+DD\n",
       "4yuSxtuclwMHl++9k+IPp5sNKA7s5yW9gaJFMm414E/K1wcDV9h+GvjFeGtHhUrns0dHf4OFtg+y\n",
       "vbntNWzPsX1GOR36yeX2D9repBysnlclCUASwaBM9I3ttvdPo+j/31heHHISMMv2d4G7ym1nAa94\n",
       "TIftxcDhFM3wmykG/gAuAN5dnrrcgyIJ/E55gcl/UQwmAiykSCS3UXQR7mVi4/FeAqwu6XbgHykG\n",
       "GMc9C8wvf4YFwGfK9w8BDivjuw3Yr8fvZ8T0d/pwUGq9+zBiFBV3H55XsfR7Zv7dhxGjKzcdRUTD\n",
       "bjpKIoioRbMeY5xEEFGLtAgiIi2CiEiLICJIiyAiaNrpw1xQFDHNJvsY/+m4oCiJICJyr0FEJBFE\n",
       "BEkEEUESQUSQRBARwP8HkwyTbf4+78QAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108298710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "y_test = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "plt.matshow(confusion_matrix)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "- measures a fraction of the classifier's predictions that are correct\n",
    "- accuracy_score() function\n",
    "  - calculate the accuracy of a set of predictions given the correct labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred, y_true = [0, 1, 1, 0], [1, 1, 1, 1]\n",
    "print 'Accuracy:', accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cross_val_score() function\n",
    "  - predicts and scores labels for a test set using accuracy\n",
    "  - accuracy may differ as the training and test sets are assigned randomly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.95596992395138047, array([ 0.94504182,  0.96774194,  0.9497006 ,  0.96047904,  0.95688623]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "df = pd.read_csv('data/SMSSpamCollection', delimiter='\\t', header=None)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1], df[0])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "print(np.mean(scores), scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- measures the overall correctness of the classifier\n",
    "- does not distinguish between false positive errors and false negative errors.\n",
    "- 장점\n",
    "  - 전반적인 예측 정확도 평가 방법.\n",
    "  - postive 예측율이나 negative 예측율에 대한 편향성이 없다.\n",
    "- 단점\n",
    "  - 실제 분류에서 positive와 negative의 비율의 차이가 크면 accuracy가 높아도 의미가 없다. 무조건 비율이 큰 쪽으로만 예측하는 경우 accuracy가 높아지기 때문이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and recall\n",
    "- positive와 negative의 가치가 다를 때 accuracy 대신 사용\n",
    "- Some applications may be more sensitive to false negatives than false positives, or vice versa\n",
    "  - Ex) To promote customer satisfaction, the credit card company may prefer to risk verifying legitimate transactions than risk ignoring a fraudulent transaction.\n",
    "  - classifiers are often evaluated using two additional measures called precision and recall.\n",
    "\n",
    "#### precision\n",
    "- fraction of positive predictions that are correct\n",
    "- classifier가 positive라고 분류한 것중에서 실제로 맞는 비율 \n",
    "$$ P = {TP \\over TP + FP}$$\n",
    "\n",
    "|         | Negative | Positive\n",
    "|---------|:--------:|:-------:\n",
    "|Negative | TN       | FP     \n",
    "|Positive | FN       | TP     \n",
    "- 장점\n",
    "  - positive로 예측한 것 중에서 맞춘 비율(혹은, 틀린 비율)이 중요할 때 사용\n",
    "    - 예) 부작용이 큰 수술을 하기 위한 진단\n",
    "- 단점\n",
    "  - positive에 대한 편향성\n",
    "    - postive 예측율만을 다루고 negative 예측율은 무시한다.\n",
    "    - positive만 중요힌 경우에 사용\n",
    "    - negative를 positive로 간주하여 추가 지표로 사용할 수도 있음\n",
    "  - 보수(conservative) 편향성\n",
    "    - classifier가 positive임이 확실한 경우에만 positive로 분류하는 보수(conservative) 성향인 경우 precision은 높지만 recall이 낮아진다.\n",
    "    - 가령, positive임이 아주 확실한 1개만 positive로 분류하고 나머지의 경우 모두 negative로 분류하면 precision은 100%이나 recall은 0에 근접하고 정확도는 떨어진다.\n",
    "\n",
    "#### recall\n",
    "- fraction of the truly positive instances that the classifier recognizes\n",
    "- 실제로 positive인 것 중에서 맞게 분류한 비율\n",
    "- Sometimes called sensitivity in medical domains\n",
    " $$ R = {TP \\over TP + FN}$$\n",
    "\n",
    "|         | Negative | Positive\n",
    "|---------|:--------:|:-------:\n",
    "|Negative | TN       | FP     \n",
    "|Positive | FN       | TP     \n",
    "- 장점\n",
    "  - 실제 positive인 것 중에서 맞춘 비율이 중요할 때 사용\n",
    "    - 예) 수술을 하지 않으면 위험한 질병에 대한 진단\n",
    "- 단점\n",
    "  - positive에 대한 편향성\n",
    "    - positive 예측율만을 다루고 negative 예측율은 무시한다.\n",
    "    - positive만 중요한 경우에 사용\n",
    "    - negative를 positive로 간주하여 추가 지표로 사용할 수도 있음\n",
    "  - 진보(liberal) 편향성\n",
    "    - classifier가 positive로 많이 분류하는 진보(liberal) 성향인 경우 recall은 높지만 precision은 낮아진다.\n",
    "    - 가령, 모든 경우에 positive라고 예측하면 recall은 100%이나 precision은 크게 떨어지고 정확도도 떨어진다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross_val_score() function calculate precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam' 'ham' ..., 'ham' 'spam' 'ham']\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ..., \n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "('Precision', 0.99002164502164514, array([ 1.        ,  1.        ,  0.975     ,  0.98701299,  0.98809524]))\n",
      "('Recalls', 0.6660869565217391, array([ 0.67826087,  0.59130435,  0.67826087,  0.66086957,  0.72173913]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "df = pd.read_csv('data/SMSSpamCollection', delimiter='\\t', header=None)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1], df[0])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "lb = LabelBinarizer()\n",
    "print(y_train)\n",
    "print(lb.fit_transform(y_train))\n",
    "y_train2 = np.array([number[0] for number in lb.fit_transform(y_train)])\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train2)\n",
    "precisions = cross_val_score(classifier, X_train, y_train2, cv=5, scoring='precision')\n",
    "print('Precision', np.mean(precisions), precisions)\n",
    "recalls = cross_val_score(classifier, X_train, y_train2, cv=5, scoring='recall')\n",
    "print('Recalls', np.mean(recalls), recalls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our classifier's precision is 0.992\n",
    "- almost all of the messages that it predicted as spam were actually spam\n",
    "- Its recall is lower, indicating that it incorrectly classified approximately 22 percent of the spam messages as ham\n",
    "- Evaluation (DT)\n",
    "  - 이 spam filter는 precision이 매우 높으나 recall이 낮은 편이다.\n",
    "  - 즉, spam이 아닌 것을 spam이라고 한 경우는 드물지만(약 1%) spam인데 spam이 아니라고 한 비율(약 30%)이 높은 편이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the F1 measure\n",
    "\n",
    "- also called f-measure, f-score\n",
    "- harmonic mean, or weighted average, of the precision and recall scores.\n",
    "\n",
    "$$F1 = \\frac{1}{\\frac{\\frac{1}{P} + \\frac{1}{R}}{2}} = 2 \\frac{PR}{P+R}$$\n",
    "\n",
    "|         | Negative | Positive\n",
    "|---------|:--------:|:-------:\n",
    "|Negative | TN       | FP     \n",
    "|Positive | FN       | TP     \n",
    "\n",
    "- $\\displaystyle F_\\beta = (1 + \\beta^2) \\frac{PR}{\\beta^2 P + R}$\n",
    "  - F0.5: favor precision over recall \n",
    "  - F2: favor recall over precision\n",
    "- penalizes classifiers with imbalanced precision and recall scores\n",
    "- P와 R이 비슷한 값일 경우 그 값의 평균(즉, P 혹은 R)에 근접한다.\n",
    "- F1 값은 2 min(P, R)보다 항상 작다.\n",
    "- F1 값은 P나 R 한 쪽이 다른 한쪽보다 휠씬 더 작은 값일 경우 2 min(P, R)에 근접한다.\n",
    "- 따라서, F1 값이 큰 값이 되기 위해서는 P와 R이 골고루 커야 한다.\n",
    "- 총 자원이 제한된 경우 (P + R = c), 최대 조화평균값은 x = y = c/2인 경우이다. \n",
    "- accuracy가 1인 것, precision과 recall이 동시에 1인 것, F1이 1인 것은 동치이다.\n",
    "- F1이 크면 accuracy도 높다.\n",
    "  - TP에 비해 FP와 FN이 모두 작으므로 accuracy가 높다.\n",
    "- 장점\n",
    "  - precision, recall 중립성\n",
    "      - precision과 recall이 모두 중요할 때 사용\n",
    "      - F1은 precision과 recall이 모두 커야 큰 값이 될 수 있다.\n",
    "  - accuracy와 달리 실제 positive, negative의 비율의 차가 큰 경우에도 measure가 왜곡되지 않는다.\n",
    "      - negative가 매우 크고(99%), negative는 모두 맞추고, 실제 positive(1%)중에서 10%만을 맞추고 모두 negative로 예측하면, TN = 99%, FN = 0.9%, TP = 0.1%, FP = 0%. 따라서, accuracy는 0.991, precision은 1, recall은 0.1, F1은 0.182\n",
    "- 단점\n",
    "  - positive에 대한 편향성\n",
    "      - positive 예측율만을 다루고 negative 예측율은 무시한다.\n",
    "      - positive만 중요한 경우에 사용\n",
    "      - negative를 positive로 간주하여 추가 지표로 사용할 수도 있음\n",
    "      - negative가 중요하거나 둘다 중요한 경우, F1은 positive로 편향된다.\n",
    "          - 실제 negative의 비율이 작은 경우(1%), positive는 모두 맞추고, negative 중에서 10%만 맞춘 경우(즉, TP = 99%, FN = 0%, TN = 0.1%, FP = 0.9%), accuracy는 0.991, precision은 0.991, recall은 1, F1은 0.995\n",
    "          - negative가 중요한 경우 적절한 평가값인 negative recall은 0.1이다.\n",
    "- DT Question\n",
    "  - positive F1과 negative F1의 조화 평균이 필요한 경우는 없는가?\"\n",
    "\n",
    "\n",
    "#### 산술평균과 조화평균\n",
    "- 산술평균\n",
    "  - $\\displaystyle \\frac{x + y}{2}$\n",
    "  - 평균이므로 x, y 둘다 커지거나 어느 한쪽만 커져도 평균은 지속적으로 커진다.\n",
    "  - 총 자원이 제한된 경우 (x + y = c), 자원을 어떠한 비율의 x와 y로 분배하든 평균은 일정하다.\n",
    "- 조화평균\n",
    "  - $\\displaystyle \\frac{1}{\\frac{\\frac{1}{x} + \\frac{1}{y}}{2}} = 2 \\frac{xy}{x+y} = 2 \\frac{x}{1+x/y} = 2 \\frac{y}{1+y/x}$\n",
    "  - 대표적인 예: 평균 속력 (시간당 거리 단위를 거리당 시간 단위로 바꿔서 평균한 후 역수를 취하여 시간당 거리, 즉 속력을 구한다.)\n",
    "  - 평균이므로 x, y 둘다 커지거나 어느 한쪽만 커져도 평균은 지속적으로 커진다.\n",
    "  - x와 y가 비슷한 값일 경우 그 값의 평균(즉, x 혹은 y)에 근접한다.\n",
    "  - x나 y 한 쪽이 다른 한쪽보다 휠씬 더 작은 값일 경우 그 작은 값의 2배에 근접한다.\n",
    "  - x가 커지면 그 값은 2y에 수렴하나 2y보다 항상 작다.\n",
    "  - y가 커지면 그 값은 2x에 수렴하나 2x보다 항상 작다.\n",
    "  - 총 자원이 제한된 경우 (x + y = c), 최대 조화평균값은 x = y = c/2인 경우이다. \n",
    "$$\\frac{1}{\\frac{\\frac{1}{x} + \\frac{1}{y}}{2}} = 2 \\frac{xy}{x+y} = 2 \\frac{x (c-x)}{x + c - x} = \\frac{2}{c}(cx - x^2)$$\n",
    "$$c - 2x = 0$$\n",
    "$$x = \\frac{c}{2}, y = \\frac{c}{2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('F1', 0.79545941505710827, array([ 0.80829016,  0.7431694 ,  0.8       ,  0.79166667,  0.83417085]))\n"
     ]
    }
   ],
   "source": [
    "f1s = cross_val_score(classifier, X_train, y_train2, cv=5, scoring='f1')\n",
    "print('F1', np.mean(f1s), f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- F1: 0.78\n",
    "- arithmetic mean: 0.815\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ROC AUC\n",
    "- ROC (Receiver Operating Characteristic) curve\n",
    "  - a graphical plot that illustrates the performance of a binary classifier system as its discrimination threshold is varied\n",
    "  - plot the classifier's recall(TPR, true positive rate) against its fall-out (FPR, false postive rate)\n",
    "  - fall-out \n",
    "  $$ F = \\frac{FP}{TN + FP} = 1 - \\frac{TN}{TN + FP} $$\n",
    "      - number of false positives divided by the total number of negatives\n",
    "      - 실제 negative 중에서 틀린 비율\n",
    "- AUC (Area under the ROC curve)\n",
    "  - reduces the ROC curve to a single value, which represents the expected performance of the classifier.\n",
    "  - The dashed line is for a classifier that predicts classes randomly\n",
    "![](roc.png)\n",
    "- DT ROC curve\n",
    "  - ROC curve보다 의미가 더 간결하고 명확하다.\n",
    "  - Recall: positive 중에서 맞춘 비율\n",
    "  - Negative Recall: negative 중에서 맞춘 비율\n",
    "  - 둘다 클수록 좋다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYXGWZ9/HvL2EPRII4jCSRKJuIwICyKhKQgYAsLggD\n",
       "uCHXADIIOPLK4My8xHFhdJRhfFEGEXCZEVBBWUQQlwjGsARZRNZIIgkgsgQSIJBA7veP52m6ulLd\n",
       "Xd1dp86pqt/nuurqOlWnzrnrdNW561nO8ygiMDMz6zOu7ADMzKxanBjMzGwAJwYzMxvAicHMzAZw\n",
       "YjAzswGcGMzMbAAnBmsZSUdKurbsOKpE0lJJ00rY7zRJKyV1xXdc0l2S3jGK1/kzOQpd8aHpBpIW\n",
       "SHpe0hJJiyXNlnSsJOXnf5pPMkslLZf0Ys3y1xts7yOSXs7PPyPpTknvKfI9RMT/RsS+Re6jlqTd\n",
       "JP0yH7OnJV0haat27b9BPLMkHV37WESsFxELCtrfFpJ+IOnx/P7vkPSJqiWDnKDeMJZtRMSbI+L6\n",
       "YfazSjJs92eyW1TqA9TjAjggIiYCrwP+HTgVOB8gIvbLJ5n1gP8Fvti3HBHHD7LN2Xn99YGzge9J\n",
       "mlT4O2kxSeMbPLYrcC3wI+C1wOuBO4DZkl5fQAyrNbFa264WlbQpcBPwJ+DNEbE+8H7gLcC6Ld5X\n",
       "M+992M20cd+j2pfViAjfKnAD5gN71T22I/AysHXd4xcCnx1mex8BbqhZXgdYCbw1L68JfJl0Yvkz\n",
       "cA6wVs36BwO3A88A84B98+OvIiWrR4BFwGeBcfX7zNv7j7qYLgc+ke9vDFwK/AV4EPh4zXozgR8C\n",
       "3837/2iD93cDcHaDx68Gvp3vT88xngY8no/xETXrDnoMal77KeBR4NukBHtVjvkp4Epgcl7/88BL\n",
       "wDJgKfDV/PhK4A35/reAr+VtLAFu7HsuP78PcB/wdF7v18DRg/x//we4coj//7S87w/l9/c48Oma\n",
       "53cC5gCL8//y/wGr1zy/EjgeeAD4Y37sv4CH8v9kLvD2mvXHAZ/On5UlwC3AFOD6vK1n83F5f17/\n",
       "ANLnazEwG9imZlsL8nG/Mx/P8fmxvWpin5vj+DPw5fz4Q3lfS3MMu7Dq92Br4Drgyfza08r+7lfx\n",
       "VnoAvuV/RIPEkB//E3Bc3WMjSgz5i/UP+WS2Xn7sP4Efk0526wJXAF/Iz+2UT07vzMsbA1vm+z8i\n",
       "nUDXBl5D+tV6TIN97g48VBPPJOB54K/zSeRW4F+A1Ui/9v8I7JPXnQksBw7Ky2vVvbd1SCfhPQZ5\n",
       "34/k+9OBFaST/+rAO/IJaosmjkHfa8/Ir10L2AB4T76/LvB94Ec1+/4VdUmMVRPDE8Bb8//kf4CL\n",
       "8nMbkk50787H58R8DFZJinn9R4EPD/H/n5b3fS4pAW4LvFDzf9wh/5/HAZsAdwMn1cV9bT42a+bH\n",
       "jsz/x3HAP+YY1sjP/R/SiXzzvLwtsEH9McjL2wOPkX74iJS85pMTEykJ/A6YXLPvV74fpIR2ZM1n\n",
       "Yed8f5O8r3GDfA/WyzF/Algj/w93Kvu7X8Vb6QH4lv8RgyeGOdT9qqH5xLCC9ItsOemk/Lb8nEgn\n",
       "yNov667Ag/n+ucBXGmxzo3xyqS1ZHA78smafN9Ts40/A7nn574Gf5/s7A3+q2/ZpwAX5/kxg1hDv\n",
       "bUo+AWzR4LkZwPJ8f3o+BmvXPH8JKSENdwymAy+ST3yDxPE3wFM1y7+i7hc+AxPDhcA3ap7bD7gn\n",
       "3/8Qqeqv9rUPMXhiWE5OpIM8Py3ve+Oax24CDhtk/ZOBy+rinj7MZ+wp8i99UknnwEHWq08M5wD/\n",
       "VrfOvTWflfnARwb7fpBKUjOBDQd5z4MlhsOBW0fz/ey1WyvqDq1Yk0lfwNG4MSJ2lzSBVP1zKnAQ\n",
       "6Zf+OsCtuW0b0omyr81pCvCTBtvbhPTr+dGa140jncAGiIiQdDHpy3gDcATwnZrtbCxpcc1LxpOq\n",
       "HfosGuJ9LSadAF4L3F/33GtJv8pfWTciltUs/ymvsyFDHwOAxyNi+StPSuuQShn7kn45A6wrSZHP\n",
       "PAzfzvBYzf1l9LcHbMyq73moY/Bkfs1w/lxz/3lgAqSGa+BMUpvEOqSS29y61y6sXZB0CvDRvN8A\n",
       "JpKOI6TPzB+biAfS//9Dkj5e89jqDHw/Cxnc0cC/AfdImg98JiIafV7rTSVVW9ow3PhcYZJ2JCWG\n",
       "34xlOxHxHPAxYI/c5e8J0knpTRExKd/Wj9TwDelLuVmDTS0k/Yp+dc3rXhUR2wyy64uAQyRtQqq2\n",
       "uDQ//hAwv2YbkyJiYkQc0BcyQ5xg8/uZAxza4OlDgZ/XLE/KJ/Q+m5Dq1Ic7Bn1x1PoksAWp+uFV\n",
       "wB6kZKJB1h+JR0gnVwByb7Qpg6/Oz4H3jWF/55CqjzbL7+WfWfV88Mr7kbQ7qbro/fk4TSJVffW9\n",
       "98E+M408BHy+7v+/bkRc0mjf9SJiXkQcERGvAb4I/FDS2kO9pma/Y+od1SucGKqlr2vqREkHkE6s\n",
       "342IPzRabyQiYjHwDVK11ErgPOAsSa/J+5wsaZ+8+vnAUZL2kjQuP7dlRDwK/Aw4U9J6+blNB+tf\n",
       "HhG3k07A3wSuiYgl+ambgaWSPiVpbUnjJb1Z0ltH8P7+CfiwpI/nWCZJ+hypmuozdet+RtLq+eT2\n",
       "LuAH+Rf+UMegkXVJyeQZSRsAp9c9/xiw6RCvH+p9XQ1sI+ng3BPnH0jtMYM5HdhN0pckbZTj30zS\n",
       "dyVNHOJ1fdYlNdI+L+mNpB8OQ1mP1K7zhKQ1JP1fUomhzzeBz+YYJGnbfIxg1eNyHnCcpJ3yuhMk\n",
       "vUtSU72pJH2g739GSk5BKkE+nv8O9j/4CfBaSSdJWjN/bnZqZp+9xomhWq6UtIT0y+Y04CvAUQ3W\n",
       "G/IX9RDrnAXsKWlbUrXSPOBGSc+QempsARARt+T9/iepEXoWqQstpLrwNUi/Np8CfkD/CazRPr8H\n",
       "7JX/kre/ktQr5W9IRfvHSUmr70Qz7PuLiNmkKp33kn5tLwC2I/WUqa3S+DP9PW++CxwbEX3VT4Me\n",
       "g5o4ap1FanR/Avgt8NO6df6LVEJ6StJZjcJusM3I7+cJUnfTL+Xtb0Wq2nlxkPf/IKlNZBrwB0lP\n",
       "k3py3UJqO2kUf61TSNV7S0jH/uK69etfe02+3U861ssYWIV4Jqkx/mekk/V5pEZ6SO0B31a6PueQ\n",
       "iLiV1OZ0Nukz9ADpc9VsiWtf4C5JS0mf0b+LiBcj4nlS77DZ+X+wMzXHPCKWAn8LHEhqhL6f1JZk\n",
       "ddRfNVrAxqULSL/Q/jJYdYOkr5Ia4Z4nNTjdVlhA1lMkTSeVuKaWHctI5Yu0FpK61/667HistxRd\n",
       "YriQ1EukIUn7k+o4NweOIdV7mvUkSftIWl/SmqRrAiBd62DWVoUmhoi4gVSMH8xBpAuHiIibgPX7\n",
       "6kvNWqS4InHr7Uqq2nqcVNJ+d0Q0rEoyK1LZ3VUnM7Bb2iJST4zHGq9u1ryImEV/20jlRcRnWLXh\n",
       "3KztqtD4XN9To5N+4ZmZdZ2ySwwPky466TMlPzaAJCcLM7NRiIgRd28vOzFcAZwAXCxpF+DpiGhY\n",
       "jRSwx0p04QNsvnAvfvn4I0z+W+A2UnfJyyIGXOHZtSTNjIiZZcdRBT4W/Xws+vlY9Bvtj+pCq5Ik\n",
       "XUTq772lpIWSPqo0x8CxABFxNfCgpHmk8XkGGz4aIq4fR2y7Jfff8TBTdrmAo7Yg9Rt/G3CvxK8k\n",
       "jpeGvCjIzMyGUWiJISIOb2KdE0awweeAk5DOOiou/MtRaWTMH0usTbro5f3AF6TeK0mYmbVKFRqf\n",
       "Ry5i/sBFlkXw4wiOJA2Q1s0liVllB1Ahs8oOoEJmlR1AhcwqO4BOV+iVz62SB68cvgFFWouIF/oX\n",
       "B5Qk3kUPtkmYWe9q+txZpzNLDI2k6RwfQDqw76EeK0mYmbVEt5UY3gFcQBqS+SQiGs5j4JKEmfUC\n",
       "lxgAIq4njbD5FPD72tLDwNVckjAzG0x3lRgGvugdpPl69yXi2eFWTy9xScLMusdoSwzdmxjGvE8n\n",
       "CTPrbE4Mhe7fScLMOo8TQ/MbWw3Yg4hfjO7lThJm1hmcGJrf2DTSROpD9lxqblNOEmZWXe6V1KyI\n",
       "BTTRc6m5Tbl3k5l1n94rMQzccO11D8cQsaw1m3VJwszK56qk0W98AnAU8DUKOBhOEmZWFieGDuAk\n",
       "YWbt5MTQYZwkzKxobnxuNWkq0jeQNihi8264NrOqcmIY3FPAMsbYc6kZThJmViWuShp+502N2FrM\n",
       "rl3dZGaj5zaGYgOYAHwBOAh4U6u6tY4sBNYiJYlDgf2B23GSMLMhODG0J5ApRCwqPwwnCTMbnhND\n",
       "j3KSMLPBODGUSZpAxHPlh+EkYWb93F21LNLWwH1F91xqRgQvRHB5Te+ms0i9m+5x7yYza5ZLDK1Q\n",
       "Ys+lZrgkYdabXGIoU5NzTZfFJQkzGwmXGFotlR7+FTiAiBfLDmcoLkmYdTc3PtuYOEmYdR8nBmsZ\n",
       "Jwmz7uDEUHXS2qS5pq8pO5SRcJIw61xODFUnbQFcTUV7LjXDScKss7hXUtVF3M/AnksHlRzRiLl3\n",
       "k1lvcImhDP3XPdwIfJSI5SVHNCYuSZhVk6uSOk0asfUw4MIi5poui5OEWXU4MVjlOEmYlcuJwSrN\n",
       "ScKs/dz43C2kLZEuKGqu6bK44dqscxSaGCTNkHSvpAckndrg+Q0lXSPpdkl3SfpIkfF0iEXAUjq0\n",
       "51IznCTMqq2wqiRJ44H7gL2Bh4FbgMMj4p6adWYCa0bEaZI2zOtvFBEv1W2r96qSKj5iaxFc3WTW\n",
       "WlWsStoJmBcRCyJiBXAxcHDdOo8CE/P9icCT9UmhZw0csfVGpNVLjqhwLkmYVUORiWEysLBmeVF+\n",
       "rNZ5wNaSHgHuAE4qMJ7OE/EcEScBbycl154xRJK4tyZJbFxulGbdabUCt91MHdWngdsjYrqkTYHr\n",
       "JG0XEUvrV8zVTn1mRcSs1oTZASL+UnYIZYrgBeBy4PKa6qb3A5+TeBC4Mt9ui2jqc2fWlSRNB6aP\n",
       "dTtFJoaHgak1y1NJpYZauwGfB4iIP0qaD2wJzK3fWETMLCbMDiUJWI+IJWWH0k51SWJ1UiniQFJV\n",
       "5QSJq0hJ4hcRLCsvUrP2yz+YZ/UtSzp9NNspsippLrC5pGmS1iBd5XtF3Tr3khqnkbQRKSk8WGBM\n",
       "3eQtwD3d2nOpGRGsiGBWBJ+MYAtgT+B+4BTgMYkrJI5xlZPZyBR6gZuk/Uh1w+OB8yPiDEnHAkTE\n",
       "ubkn0oXA60hJ6oyI+F6D7fRer6Rm9GDPpWZJTAJmkEoTM8BVTtZ7fOVzr0pjLn0BOAT4GBH1pbKe\n",
       "V1fldCAwAVzlZN3PiaHXpdLDPwKH4C6/Q5LYgv4ksQOpTvYq4KoIHikxNLOWcmIwGwVXOVk3c2Iw\n",
       "GyNXOVm3cWKwxqRXkS6Q+0nZoXQaVzlZp3NisMakN5G6Cbvn0hi4ysk6kRODDc49l1rKVU7WKZwY\n",
       "bHgDr3v4CBEvlxxRVxikyulK4CeucrIyOTFYc1Lp4UAiLi47lG7kKierEicGs4pxlZOVzYnBrOJc\n",
       "5WTt5sRgYyPtQJoP4xPuuVQ8VzlZO1RxBjfrLPcBT9PFc01XSQSLI7gogiOAjUgjwk4kDR++SOJc\n",
       "iQMk1i41UOtJLjHYQB6xtXSucrJWcVWStU7/dQ97AdsRsbLkiHqWq5xsLJwYrPWkDVxiqA73crKR\n",
       "cmIw6zGucrLhODFYe0jjgFcRsbjsUKyfq5ysEScGaw9pD+B7eMylynKVk/VxYrD2cc+ljuIqp97l\n",
       "xGDtlXounQG8DziOiCtLjsia4Cqn3uLEYOVIVUvHAB90t9bO4iqn7ufEYGZj4iqn7uPEYGYt4yqn\n",
       "7uDEYNUibQTsSMRVZYdiY+Mqp87lxGDVIm0HXAb8Fvdc6iqucuocTgxWPe651PVc5VRtTgxWXann\n",
       "0gXADcBRdMKHzkasQZXTOqQqp6twlVMpnBis2lLpYW8iLi87FGsPVzmVz4nBzCrLVU7lcGIws47g\n",
       "Kqf2cWKwzpTaH44GTnbPpd7kKqfieM5n61Rz6Z9r+sCyg7H2i+D+CL4SwXRgE+AiYE/gLom5EqdL\n",
       "7CDhH4dt4hKDVUN/zyVf92CAq5xawVVJ1vn6r3vYBdjZ3VqtlqucRs6JwbqHNJGIJWWHYdXlXk7N\n",
       "qWQbg6QZku6V9ICkUwdZZ7qk2yTdJWlWkfFYh3BSsGFEsDiCiyI4AtgIOAVYD/g+cKvEoRLjSw2y\n",
       "gxVWYpA0HrgP2Bt4GLgFODwi7qlZZ31gNrBvRCyStGFEPNFgWy4x9DppdWA9tz3YUCTGAfsDpwKv\n",
       "Bf4D+HYEL5QaWEmqWGLYCZgXEQsiYgVwMXBw3TpHAJdGxCKARknBLNsb91yyYUSwMoKrItgd+DDw\n",
       "LmC+xGkS65ccXscoMjFMBhbWLC/Kj9XaHNhA0q8kzZX0wQLjsU4W8VPSD4mzkL6LtEHZIVm1RTA7\n",
       "goOAvwXeCPxR4ksSG5ccWuUVmRiaqaNandS7YH9gX+BfJW1eYEzWySJ+DWwLLMalB2tSBHdF8GFg\n",
       "e2AN0vUR5+VeTtbAagVu+2Fgas3yVFKpodZC4ImIWAYsk3Q9sB3wQP3GJM2sWZwVEbNaGq11hojn\n",
       "gBORLgUOR7rK3VqtGRE8BJws8VngBOA3EtcDX4zglnKjaw1J04HpY95OgY3Pq5Ean98JPALczKqN\n",
       "z28EziaVFtYEbgIOi4i767blxmczaymJCaThWD4JzAO+CFzXTV1dK9f4HBEvkbLytcDdwCURcY+k\n",
       "YyUdm9e5F7gGuJOUFM6rTwpmZkWI4LkIvgpsBnwLOJPU1fWwXu/q6gvcrLtI04BtPFucjVSDrq5f\n",
       "Br7VyV1dK1diMCvJq3HPJRuFBl1d96dHu7o6MVh3ibgV91yyMer1rq5ODNZ9Ip4j4kT6r3v4JpKr\n",
       "Im3EerWrqxODda/+6x4ucZdWG4sIHorgZNJFuYtIXV1/KLFjyaEVwo3PZmYj1CldXT3stplZm+XJ\n",
       "hP6O1JNpOSlBXBrBS6UGlrU8MUh6lsGHtYiImDjSnY2WE4O1nHQAcBieLc5aoK6r68bAaRF8v9yo\n",
       "XGIwG5n+2eLeBxzn6x6sVSR2By4Hto7g0XJjaX2JYcg+4NHGX1lODFYYzzVtBZD4T4AIPlFuHK1P\n",
       "DAsYYoTUiHj9SHc2Wk4MVqj+0sO2REwvORrrAhKvBf5AyaUGVyWZjZU0IY/eajZmVSg1FJoYJE0i\n",
       "9d9dq++xiLh+pDsbLScGM+s0VSg1FJYYJP09cCJpPoXbgF2AORGx12gCHQ0nBiuNtA6wltsebDTK\n",
       "LjUUOYjeSaT5mxdExJ6kS8OfGemOzDrUDDzmko3el4AP59JDx2gmMbyQZ1hD0lp5DoUtiw3LrCIi\n",
       "LsNzTdso5SqkbwOfKjuWkWgmMSzMbQw/Bq6TdAWwoNCozKrEc03b2HRcqWFEvZLyfKITgWsiYnlR\n",
       "QTXYr9sYrBrSdQ/7E3Fq2aFY5yirraHIxuddgLsjYklenghsFRE3jSrSUXBiMLNOVlYPpSITw+3A\n",
       "DhGxMi+PB+ZGxPajinQUnBjMrNOVUWoodGrPvqSQ778MvT1RttkqpK3d9mDD6Ji2hmYSw3xJJ0pa\n",
       "XdIakk4CHiw6MLMOMwH3XLIhdFIPpWYSw3HA24CHSTMX7QIcU2RQZh0n4mbcc8mG1xGlBo+VZNZq\n",
       "/SO2XkvE8WWHY9XSzraGIhuftwS+Dvx1RGwtaVvgoIj43OhCHTknBus4acTW7Yn4TdmhWLW0s4dS\n",
       "kY3P5wGfJk1bB/B74PCR7sisp0Q856RgjXRCW0MziWGd2msWIhUxVhQXkplZ16t0W0MzieFxSZv1\n",
       "LUg6BMqdrs6sY0lHuueSVb3U0Ewbw6bAN4BdgaeB+cCREbGg8Oj6Y3Abg3UHzzVtWTvaGgqfwU3S\n",
       "uoCAZ4FDI+KSke5stJwYrOt4rmmj+B5KRcz5vC5wLLApcBfw38DBwOeBeRFx0OjDHWGQTgzWjfpL\n",
       "D28g4oCyw7H2K7rUUERiuAxYAswB9iHN4PYCcGJE3D6GWEfMicG6mrQWES+UHYaVo8hSQxGJ4c6I\n",
       "2DbfH09qcN6kb9KednJiMLNuVWSpoYjrGF7uu5MHznu4jKRg1pOk9d1zqTdUsYfSUCWGl4Hnax5a\n",
       "G+hLDBEREwuOrTYWlxist0hHkvq6u+dSDyiq1FB4r6QyOTFYT3LPpZ5SRFtDofMxmFkJPNd0r6nM\n",
       "1dCFJgZJMyTdK+kBSYPOkStpR0kvSXpvkfGYdZw05tKJwBGkJGFdqkptDYVVJeWeTPcBe5PmcrgF\n",
       "ODwi7mmw3nWk9owLI+LSBttyVZKZdb1WtzVUsSppJ9KFcAsiYgVwMekCuXofB34IPF5gLGZmlVeV\n",
       "UkORiWEysLBmeVF+7BWSJpOSxTn5oeq3hJtVibSz2x66TultDUUmhmZO8mcB/5SH8la+mVnzxuG5\n",
       "prtKLjX8L2lIolKsVuC2HyYNo9FnKqnUUOstwMWSADYE9pO0IiKuqN+YpJk1i7MiYlZLozXrRBFz\n",
       "SLMqnkHqueTrHrrD1cApI32RpOnA9LHuvMjG59VIjc/vBB4BbqZB43PN+hcCV0bEZQ2ec+Oz2XD6\n",
       "r3u4koiTyw7HRk9iEvAnYIMIXhr9dkZ37iysxBARL0k6AbgWGA+cHxH3SDo2P39uUfs260kRv86l\n",
       "h63KDsXGJoLFEouAbYDb2r1/X/lsZlZBEt8EfhfB10e/jep1VzWzqsgNedZR5gC7lbFjJwaz3nCc\n",
       "ey51nN/ixGBmBfoOHnOp09wHrC/x1+3esRODWS8YOOaSr3voABGsBG4Edm33vp0YzHrJwBFbzxlm\n",
       "bSvfbykhMbhXklmvklYnjWNmFSXxTuAzEbx9dK/3RD1mZl1FYj3gz8CkCJaP/PXurmpmYyX9ldse\n",
       "qiOCpcD9wPbt3K8Tg5nVOhD3XKqatl/P4MRgZv0izsc9l6qm7dczODGY2UD9PZeeIpUeDio5ol43\n",
       "B9hNat+0BE4MZraqdN3DScDhwLSSo+l1D5IGPJ063IqtUuR8DGbW6SKuB64vO4xeFkFIr1zP8FA7\n",
       "9ukSg5lZ9bW1AdqJwcxGTtrLbQ9t1dYGaCcGMxuNF4Ez3XOpbW4F3iSxTjt25sRgZiMXMRvYDvdc\n",
       "aosIlgF3AW9tx/6cGMxsdAb2XDoT6Utlh9Tl2jagnnslmdnYRFyPtB3w+rJD6XJzgCPbsSMPomdm\n",
       "1gEkpgC3AX8VQVMnbg+iZ2bVI/kc0yIRLAJeADYtel/+p5lZkU5xz6WWaku3VScGMyvS13DPpVZy\n",
       "YjCzDrdqzyWXHsZmDm3omeTGZzNrD2kC8AVgXSKOLjucTiSxBqkEtnEES4Zf31N7mlknkMYT8XLZ\n",
       "YXQqiRtI80D/fPh13SvJzDqBk8JYFd7O4MRgZuWTprrtoWlODGbWE/rmmnbPpeHNAXaWijt/OzGY\n",
       "Wfkivo57LjUlgr8ATwJbFbUPJwYzq4Y0W1ztiK0HlBxRlRXabdWJwcyqY+B1DxuWHU6FFdrO4O6q\n",
       "ZmYdRmI74JII3jj0eu6uambWK+4CNpZ4dREbd2Iws84hHeyeSxDBy8DNwC5FbN+Jwcw6yZO451Kf\n",
       "ORTUzlB4YpA0Q9K9kh6QdGqD54+UdIekOyXNlrRt0TGZWYeK+A2ea7pPYVN9Ftr4LGk8cB+wN/Aw\n",
       "cAtweETcU7POrsDdEfGMpBnAzIjYpW47bnw2s4GkdwAXABcR8a9lh9NuEpOAh4BJEbzUeJ1qNj7v\n",
       "BMyLiAURsQK4GDi4doWImBMRz+TFm4ApBcdkZt2g/7qH75QdShkiWAwsBLZp9baLTgyTSYH3WZQf\n",
       "G8zRwNWFRmRm3SNd9/BA2WGUqJDrGVZr9QbrNF1PJWlP4KPA2wZ5fmbN4qyImDWmyMyse/XO0N5z\n",
       "gR37FiRNB6aPdaNFJ4aHgak1y1NJpYYBcoPzecCMiFjcaEMRMbOIAM2sK81EmgacRMRTJcdSpPuA\n",
       "I/sW8g/mWX3Lkk4fzUaLrkqaC2wuaZqkNYDDgCtqV5D0OuAy4AMRMa/geMysN/w7vdFz6T5gi1Zv\n",
       "tPAhMSTtB5wFjAfOj4gzJB0LEBHnSvom8B5S6zrAiojYqW4b7pVkZiPX33NpDl1YepAQsBSYEsHT\n",
       "qz7vqT3NzFbVP9d0EHFy2eG0msTvgOMiuHnV50Z37iy6jcHMrFwRzwEnIXXrSA991UmrJIbR6tYD\n",
       "ZWY2UMTKskMoyP3Alq3coBODmfUuabMuGHOp5Q3QTgxm1su6Ya7p+2lxYnDjs5n1tg7vuSQxEXgU\n",
       "WC+ClQOfq+ZYSWZm1bbqXNPvKjmiEYlgCbAE2LhV23RiMDMbONf02mWHMwotbYB2d1Uzsz6p9NCJ\n",
       "+toZftGKjbnEYGbW+VraM8mJwcxsONIHK95zqaVVSU4MZmbDW0C155p2icHMrK0ibqDac03PB6ZK\n",
       "rNmKjTkxmJk1Y2DPpTOR/qXskPpEsJw0QvUbWrE990oyMxuJiOuRtgNeXXYodfqqk+4Z64acGMzM\n",
       "RiqN2Ppc2WHUaVkDtKuSzMxaRVq9xL23rAHaicHMrHW+VGLPJZcYzMwq6F8or+dSy0ZZ9eiqZmat\n",
       "VsKIrY3mf/boqmZmVTFwxNa2zDMdQdCiUoN7JZmZFaF/rul21na0ZP5nlxjMzIrU3vr6lpQYnBjM\n",
       "zNpNenNBPZda0jPJicHMrP3eRTE9l1pyLYN7JZmZlaGAnkv18z+7V5KZWSdZda7p/ca+ydbM/+zE\n",
       "YGZWloEjtq5s0VbH3ADt7qpmZmVr7VzTfQ3QvxztBlxiMDPrLmNugHZiMDOrKun4UfRcGnOXVScG\n",
       "M7PquouRzzXtEoOZWddatedSM6WH+cAUiTVGu1snBjOzKlt1rulThl6d5cBCYNPR7tK9kszMOkH/\n",
       "XNPrNrH2mKqTnBjMzDpF83NNj6kButCqJEkzJN0r6QFJpw6yzlfz83dI2r7IeMzMupK0Zt0jYyox\n",
       "FJYYJI0HzgZmAG8CDpe0Vd06+wObRcTmwDHAOUXF0y0kTS87hqrwsejnY9GvR4/F2XU9l8Z09XOR\n",
       "JYadgHl2gnpXAAAHIklEQVQRsSAiVgAXAwfXrXMQ8G2AiLgJWF/SRgXG1A2mlx1AhUwvO4AKmV52\n",
       "ABUyvewASnAyA3sujakqqcg2hsmklvE+i4Cdm1hnCvBYgXGZmXWX/tniLgUuWInmbMgTE0Y7XGuR\n",
       "JYZmx/OuHxK2+uOAm5lVUb7uQfDUyZz19Gg3U2SJ4WFgas3yVFKJYKh1puTHViHJCSOTdHrZMVSF\n",
       "j0U/H4t+PhYAnxv1K4tMDHOBzSVNAx4BDiNdoFHrCuAE4GJJuwBPR8Qq1UiepMfMrH0KSwwR8ZKk\n",
       "E4BrgfHA+RFxj6Rj8/PnRsTVkvaXNI/UN/eoouIxM7PmdMTUnmZm1j6VGivJF8T1G+5YSDoyH4M7\n",
       "Jc2WtG0ZcbZDM5+LvN6Okl6S9N52xtcuTX4/pku6TdJdkma1OcS2aeL7saGkayTdno/FR0oIsy0k\n",
       "XSDpMUm/H2KdkZ03I6ISN1J10zxgGrA6cDuwVd06+wNX5/s7AzeWHXeJx2JX4FX5/oxePhY16/0S\n",
       "uAp4X9lxl/SZWB/4AzAlL29YdtwlHouZwBl9xwF4Elit7NgLOh67A9sDvx/k+RGfN6tUYvAFcf2G\n",
       "PRYRMScinsmLN5F6dHWjZj4XAB8Hfgg83s7g2qiZ43AEcGlELAKIiCfaHGO7NHMsHgUm5vsTgScj\n",
       "4qU2xtg2EXEDsHiIVUZ83qxSYmh0sdvkJtbpxhNiM8ei1tHA1YVGVJ5hj4WkyaQTQ9+QKt3YcNbM\n",
       "Z2JzYANJv5I0V9IH2xZdezVzLM4Dtpb0CHAHcFKbYquiEZ83qzS6qi+I69f0e5K0J/BR4G3FhVOq\n",
       "Zo7FWcA/RURIEqt+RrpBM8dhdWAH4J3AOsAcSTdGxAOFRtZ+zRyLTwO3R8R0SZsC10naLiKWFhxb\n",
       "VY3ovFmlxNDSC+I6XDPHgtzgfB4wIyKGKkp2smaOxVtI18JAqk/eT9KKiLiiPSG2RTPHYSHwREQs\n",
       "A5ZJ6pv9q9sSQzPHYjfg8wAR8UdJ80ljB81tS4TVMuLzZpWqkl65IE7SGqQL4uq/2FcAHwIY6oK4\n",
       "LjDssZD0OuAy4AMRMa+EGNtl2GMREW+IiNdHxOtJ7Qwf67KkAM19Py4H3i5pvKR1SA2Nd7c5znZo\n",
       "5ljcC+wNkOvTtwQebGuU1THi82ZlSgzhC+Je0cyxAP4vMAk4J/9SXhERO5UVc1GaPBZdr8nvx72S\n",
       "rgHuBFYC50VE1yWGJj8TXwAulHQH6QfwpyJitGPKVZqki4A9gA0lLQROJ1Urjvq86QvczMxsgCpV\n",
       "JZmZWQU4MZiZ2QBODGZmNoATg5mZDeDEYGZmAzgxmJnZAE4M1jEkrZT05ZrlU4qYwlHSp+uWZ7do\n",
       "uy/nIbHvlHSZpHVbsd2a7S+QtEG+/2wrt229xYnBOsly4D2SXp2Xi7oI57TahYho1ThUz0fE9hGx\n",
       "LbAEOLZF2+0Tg9w3GxEnBuskK4BvAJ+of0LSayT9UNLN+bZbzePX5clazqv7Vf2jPArpXZL+Pj/2\n",
       "78Da+Zf9d/Njz+a/F0vav2af35L0XknjJP1H3u8dko5p4r3MATbN29lU0k9zLNdL2jI/vlGO8fZ8\n",
       "22WwuM1aquxJJnzzrdkbsBRYD5hPGmP/k8Dp+bnvAW/L918H3J3vnw2cmu/vSxoqYoO8PCn/XRv4\n",
       "fc3y0vr95r/vBr6V768BPASsCRwD/HN+fE3gFmBao/jz3/HApcDxefkXwGb5/s7AL/L9S4AT8/1x\n",
       "wMRh4p5f896WNjqGvvnWzK0yYyWZNSMilkr6DnAisKzmqb2BrfK4UQDrSZpAGo783fm110qqHYX2\n",
       "JEnvzvenkuYzuHmI3V8D/FceuG0/4NcR8aKkfYBtJB2S15sIbAYsqHv92pJuI42PvwD479zOsCvw\n",
       "g5rY18h/9wQ+kGNfSap+Gk3cZiPixGCd6Czgd8CFNY8J2DkilteumE+2q8zPIGk6ad6CXSLiBUm/\n",
       "AtYaaqd5vVmkksehwEU1T58QEdcNE/eyiNhe0tqkAeAOBn5OGu1ysHl4B8Q+mrjNRsptDNZxIs09\n",
       "8X3SzHV9jaw/I5UiAJC0Xb47m3QSJ/+yn5QfnwgszifXNwK71OxihaTBfjRdQpoYaXdSCQLSSf74\n",
       "vtdI2iIPez1Y/MtyrJ8HngXm95U2lGybV/0F8LH8+HhJE4eJ26wlnBisk9T2tPkKaVKePicCb82N\n",
       "v3+gv8fPZ4B9JP0eOAT4M6mt4hpgNUl3A2eQGoP7fAO4s6/xuW6/PwPeAVwX/XMIf5M078Hv8n7O\n",
       "oXFp/JXtRMTtpAntDwWOBI6WdDtwF2mOXkjTUe4p6U7SHARbDRN3w32ZjZSH3baultsDXo6IlyXt\n",
       "CnwtInYoOy6zKnMbg3W71wHflzSOdB2Eu3eaDcMlBjMzG8BtDGZmNoATg5mZDeDEYGZmAzgxmJnZ\n",
       "AE4MZmY2gBODmZkN8P8BWuuPpL3/b1cAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x73ebe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('DT Receiver Operating Characteristic')\n",
    "negative_recall = [1, 0.98, 0.95, 0.9, 0.8, 0.4, 0]\n",
    "recall = [0, 0.2, 0.4, 0.55, 0.62, 0.8, 1]\n",
    "plt.plot(negative_recall, recall)\n",
    "plt.plot([0, 1], [1, 0], 'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Negative Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 구분 능력이 없는 순수한 random 예측인 경우\n",
    "  - 대각선은 구분 능력 없이 일정한 확률 p로 positive로 예측하는 경우 reall과 fall-out이 모두 p임을 의미함\n",
    "- 실제 negative 중에서 틀린 비율과 실제 positive 중에서 맞춘 비율을 분류 기준(logistic regression에 의한 확률의 threshold 값)에 따라 각각 x, y축 좌표로 표시\n",
    "  - test data에 대하여 logistic regression에 의해 예측한 확률 분포가 동일하더라도 분류 기준에 따라 ROC curve상의 TPR, FPR(fall-out)이 달라짐\n",
    "      - 보수적(conservative) 기준 (threshold 값이 크다)\n",
    "          - Postive임이 확실한 경우에만 Positive로 분류하고 나머지는 Negaive로 분류함\n",
    "      - 진보적(liberal) 기준 (threshold 값이 작다)\n",
    "          - Postive임이 불확실하지만 가능성이 있어보이면 무조건 Positive로 분류하고 나머지는 Negaive로 분류함\n",
    "      - 중립적(neutral) 기준 (threshold 값이 적정하다)\n",
    "          - 적정 확률 수준에서 Positive와 Negative를 분류한다.\n",
    "- 가능하면 recall은 높되, fall-out은 낮은 값이 좋다. (좌표의 상단 왼쪽편)\n",
    "- 가장 뛰어난 예측 능력을 가진 classifier의 ROC curve\n",
    "  - positive data에 대하여 1의 확률로, negative data에 대하여 0의 확률로 예측하는 것이다.\n",
    "  - 이 경우, ROC Curve는 좌표점 (0,1)이다.\n",
    "- AUC가 1인 완전 예측 classifier의 ROC curve\n",
    "  - 특정 확률 p(0.5 등)에 대하여 그 이상의 확률이면 실제 데이터가 positive이고, 그 미만이면 실제 데이터가 negative인 경우이다.\n",
    "  - threshold가 특정 확률 p보다 점점 크게 하면, fall-out은 0이고, recall은 점점 작아진다. (좌표의 recall 축)\n",
    "  - threshold가 특정 확률 p보다 점점 작게 하면, recall은 1이고, fall-out은 점점 커진다. (좌표의 상단 수평선)\n",
    "  - AUC가 1이라는 것은 무조건 완전한 예측(positive와 negative를 모두 완전히 예측)을 한다는 것이 아니라 적정 threshold 값을 찾으면 완전한 예측을 할 수 있음을 의미함.\n",
    "- 장점\n",
    "  - positive에 대한 편향성이 없다.\n",
    "      - positive recall과 negative recall을 동등하게 표시한다.\n",
    "      - positve와 negative 비율의 차이가 커도 ROC curve는 영향을 받지 않는다. (accuracy, precision, recall, f-measure는 영향을 크게 받을 수 있다)\n",
    "  - 포괄적 분류 기준\n",
    "      - 주관적 분류 기준과 관계없이 내부적인 구분 능력(예측된 확률)을 나타낸다.\n",
    "      - unlike precision and recall, the ROC curve illustrates the classifier's performance for all values of the discrimination threshold\n",
    "      - 목적에 따라 원하는 수준의 recall과 fall-out 값에 해당하는 threshold 값을 사용할 수도 있다.\n",
    "- 단점\n",
    "  - precision, recall 요소를 포함하지 않는다.\n",
    "  - 특정 threshold 확률에 대하여 완전한 예측이 가능하기만 하면(즉, AUC가 1) 얼마나 더 적정한 확률로 예측했는지를 변별하지는 못한다. 가령 threshold가 0.5인 경우와 0.99인 경우를 구분하지 않는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuYHGWZ/vHvTQ5ESAIJLBCTgYjEcAokgJFV0QAuBhYD\n",
       "6BJADouuosjpx4KLh1XB1RVlUQkuiCwiIAkLgiy/BTkozgUqCogQzkkwQBKOIRGEBEiYZ/94azLd\n",
       "k55Jz6Srq7vn/lxXX5nuqq56utJdT1W9T72vIgIzM7NOGxQdgJmZNRYnBjMzK+PEYGZmZZwYzMys\n",
       "jBODmZmVcWIwM7MyTgy2TpIekvSBouNoFJK+KOnigtb9E0n/VsS6a03SkZJu6ed7/Z3MkRNDk5H0\n",
       "pKQVkv4q6TlJV0gamec6I2LniLgjz3V0krShpG9Jeir7nPMknV6PdfcQzzRJi0pfi4hvRcSnc1qf\n",
       "JJ0s6UFJr0paJOlqSTt3rj57FErSmZKuWJ9lRMSVEfHhKta1VjKs53dyIHJiaD4BHBgRI4BdgUnA\n",
       "vxYbUt9JGtzDpGuAvYH9geHA0cBxks7LIQZJUq2Xu57OA04GTgJGAe8CrgcOqPWKJA2q9TKbYd1W\n",
       "hYjwo4kewEJgn5Ln3wFuLHm+J/A7YDlwP/DBkmmjgUuBJcAy4Ocl0w7M5l8O/BaYVDLtSWAf4O3A\n",
       "CmBUybQpwIvAoOz5J4FHsuXfDGxdMm8H8DlgPvBEhc+2L7ASGNvt9anAamDb7Hk78C3gD8DLpB3n\n",
       "qCq3QTvwjewzrgDeCXwii/kV4AnguGzejbN43gL+mk0fA5wJXJHNMz77XMcAT2Xb4ksl63sbcFm2\n",
       "PR4B/gVY1MP/7YTsc+7Ry///pcAPgP/N4vl953bJpp8HPJ1tl3uB95dMOxP4GXBFNv2TwLuBu7Jt\n",
       "9QxwPjCk5D07AbcBLwHPAV8EPgy8AbyZbZc/ZfNuAlySLWcx8G/ABtm0Y7Nt/l1gaTbtWODObLqA\n",
       "7wHPZ7HNzdZ9XLaeN7J1/U/Jd3Lf7O9BwJeABdk2uRcYV/RvtZkfhQfgRx//w1Ji6PxBjMt+QF/N\n",
       "no/NfnTTs+cfyp5vlj2/EZiT/YAHA3tlr0/JfpDvzn6gx2TrGVKyzn2yv38FfKoknnOAC7K/DyLt\n",
       "9CeSzka/DPy2ZN4O4BZgU2DDCp/tbODXPXzuJ4FPZ3+3ZzueHYGNOnd2VW6D9mxZO2QxDiYdjb8j\n",
       "m/4B4DVgSvb8g3TbkQNfY+3EcBGwIbAL8DowsfQzZdt8bPb/9XQPn/GzwMJ1/P//JPs8e2Q7xJ8C\n",
       "c0qmH0k609gA+GfgWWBoNu1M0k52RvZ8GLAbKfFuAGxDSl6nZNNHZO8/FRhKOoObWrINLu8W28+B\n",
       "C0nJ8G9IibszyR4LrAJOyNY1jPLE8GHSDn1k9nwisFX296XA1yv8Djq/k5/PtuuE7PkkYHTRv9Vm\n",
       "fvhSUvMRcL2kV0hHhk+QjoABjgJuioibASLil6Qf299LGgNMBz4bES9HxOqIuDN733HARRFxTySX\n",
       "k47Q9qyw/tnAEZAuxQCHZa9B2rF9KyIej4gO0lH9ZEltJe//VkT8JSLeqLDszUlHpZU8m02HdDnt\n",
       "8oh4JCJWAF8BZkraoLdtUPLen0TEoxHRkW2HmyJiYTb/HcCtwF7Z/JUuNVV67ayIeCMi5gIPkC7z\n",
       "ARwK/Hu2zZeQjuh7uny1WS+fv1MA10XEvRHxFnAlMHnNxHTdfnn22b5LSlYTS97/u4i4IZv39Yi4\n",
       "LyLuzuZ/CvgRKRlCOot8JiK+FxFvRsSrEXF3yTZY8zkkbUm6/HdqRKyMiBeB7wOHl6z7mYj4z2xd\n",
       "r3f7XKtIiWgHSRtk36HSbdHbJb9PAV+OiPnZ53owIpb1Mr+tgxND8wngoIgYCUwjXeLZI5u2DXCo\n",
       "pOWdD+B9wFZAG7AsIl6usMxtgNO6vW8c6dJRd9cBfytpK9LRdUdE/KZkOeeVLOOl7PWxJe8va8jt\n",
       "5kXSpZpK3k46Uq60nKeBIaTE0ds2qBiDpP0l/V7SS9n8B5B20n1RuhNbQTq67oy7dH2Le1nGS/T8\n",
       "+Us9X/L3ypJ1Iel0SY9I+kv2WTahK6GutX5J75L0v5KelfQy8E26Pnsb8Ocq4oG03YcAz5Zs9x+S\n",
       "zhw69fh/HxG3ky6R/SfwvKSLJI2oct3jSAdIViNODE0sO7o9H/h29tLTpEsco0oeIyLiO6Qf5WhJ\n",
       "m1RY1NPAN7u9b3hE/HeFdS4nHVEfBnycdGmqdDnHdVvOxhHx+9JF9PKRfgm8R9K40hclvYf047+9\n",
       "5OWtu/29ipRYetsGa8UgaUPgWlJbzRYRMQq4ia4j1Erx9qUq6FnSDrZTW08zki7TjZO0ex+Wv4ak\n",
       "vUiXVQ6NiE2zz/Iy5Ufb3WO/kHT5aLuI2IR0+a9zv/A0sG0Pq+vo9nwR6Sxzs5LtvklETOpl3WUi\n",
       "4vyI2IN0ifBd2WdZ5/uydW+3jnmsD5wYmt/3ganZzvOnwEck7SdpkKRhWbnl2Ih4FvgFcIGkTSUN\n",
       "KakDvxj4rKSpWaHOxpL+XtLwHtY5G/hH4GN0XUaCdIT4JUk7AkjaRNKh1X6QiPgVaed4raQds8+w\n",
       "J6mx9IKI6DwqFHCUpB0kbQR8HbgmIqK3bVCyqtId5dDssRTokLQ/sF/J9OeBzbqVBPelkulq4IvZ\n",
       "Nh8LnEgPO7rsUsgFwBxJH5Q0NIv/cElnVLHuEaTG66XZe78KrKuUeTipUXeFpO2B40um3QiMkXRK\n",
       "VkY8QtLUbNrzwPjOqq7s+3Ur8N1svg0kvVNV3msgaQ9J75E0hHTG9Tqp0b9zXT0lKID/Av5N0nbZ\n",
       "93cXSaOrWa9V5sTQ5CJiKanq5YyIWExqAP4S8ALpiO80uv6fjyYdWT9G+rGdnC3jj8CnSafyy0gN\n",
       "yMfQ85HaDaQjtGcj4sGSWK4nnb1clV2WeJDUqLhmlio+0sdIjbU3k3ZYVwD/FREndVvOFaSG2GdJ\n",
       "O/bOz9LTNqh41BwRf83ee3X22Y8A/qdk+mOks6I/S1qWtdV0v5egt8/1ddLlm4WkHec1pAbgiiLi\n",
       "ZLouqSwnVdocRNrmnevqvr7O5zdnj3mkBvaVpM9fOl/3955OOvN7hdS+cFXnPNm2+TvgI6TtPI90\n",
       "+ZLscwC8JOne7O9jSP8XnVVp19B1Ca+nuDtfG5mtf1kW+1JSYQOkSqcds0tU17G275L+/24lnSFd\n",
       "TGrctn5SOsjKaeHSj0mNfi90O6UsnWcWqdFqBXBsRPwpt4CsJUj6Nely0Y+LjqWvJB0PzIyIvYuO\n",
       "xawneZ8xXEqqhKlI0gGka5sTSJUxF+Ycj7WORrsxrSJJW0l6X3ZpZSKphPTnRcdl1ptcE0NWDrm8\n",
       "l1lmkC6DEBF/ADbNyt7M1qXwbiGqNJTU9vIKqf3kelI7glnD6qlbgnoZy9qlfOMoL8czK9NMl2Ei\n",
       "4mnSDVdmTaMRGp+7XxJoliNBM7OWVPQZwxLK67rHZa+VkeRkYWbWDxHR5/a4ohPDDaS67quyevW/\n",
       "RETFy0j9+XB5k5gBbF/ftR7yd/Dz2+q7zkbVsttiB1KXGp1dnXQAt0awoqc3SDozIs6sQ2wNb8Bu\n",
       "C2kKqYR7EXAcEc/096A618QgaQ6p35XNlfq0/xrptnki4qKIuEnSAZIWkDou+0Se8dSSxBhS/fRv\n",
       "qWubyNs2oryLgwGsZbfFi8DXI7i+6ECsSUinknq+PR24gvW8DyHX+xhqRVI0yhmDxGBSu8ilpKO6\n",
       "D0XULzEM2KOhCrwtunhbdBmQ20J6P/BnIp4pf7l/+86iLyU1FYmt6KqiCmBGPZNCpr3O62tk7UUH\n",
       "0EDaiw6ggbQXHUDddXVkWRM+Y6hq/WxIGqxkNDA0gncVFYuZWbV8xrCesrOB0p4lSw0j9Xm/N+Vd\n",
       "P5uZ1Yc0lLSP+gsR38tzVU2dGCQEfJQ0itf62pnUq+asHqbfGMEfa7AeM7O+6V5xlPfqmvFSksTm\n",
       "pOELRwF3knpWrIU7I/hRjZZlZrZ+us4SjqcfFUf9vZTUrInhQVI3vW8CT0T03FGfmVnTki4gDUR1\n",
       "XPeKo+rePrASw+OkiqDHCwzLzCxfaXjTV/t7X8KAaXyW2Jg07F/3oQXNzFpLGiyp7hqhE72++ofs\n",
       "Xw/+bWatQRqKtFnRYXRqxsTwUWBOhM8YzKwFpIqje4DPFR1Kp6a7lAQMAq4tOggzs/VSqeKoQTTV\n",
       "GYPErqQxpH2TmZk1r66zhN2ByURcvr4d39VS01QlQWwI3Assi2BawSGZmfWf9M+kA9z17gm199W0\n",
       "eLkqxJHAlcCWEbxQdExmZo1uICSG3wMLI/h40fGYmTWD/iaGZmpjmAJcUnQQZmZVk6Yg7V10GH3V\n",
       "TIlhKfhOZzNrAum+hLOAW4CGuT+hWs1UrjoWeL3oIMzMelXeE+rk/vRxVLRmOmOYH+EyVTNrYNKJ\n",
       "pLOEc4GPNGNSgOY6Y1hVdABmZutwF016llCqmRLDyKIDMDPrVURLDObVTJeS5hYdgJnZQNBMZwzn\n",
       "Fx2AmVlJH0cdRJxVdDh5aKYzBjOzYpX3cXRxwdHkxonBzGxdyu9LaOqKo2o006UkM7OifBPYgRao\n",
       "OKqGE4OZ2bp9FXi9kbrGzpMTg5nZukSsLDqEemqmNoZCBsU2swEktSVsVXQYRWumxPC7ogMwsxbW\n",
       "VXF0ctGhFM2XksxsYGvgsZeL4sRgZgNXC/SEmodmGsFtgwgaP1gzax7Sp4A3yXns5aIMhKE9nRjM\n",
       "zPpgIAztaWZmdeDEYGatL429fGDRYTSLXBODpOmSHpM0X9IZFaZvLulmSfdLekjSsXnGY2YDTHkf\n",
       "RxsXHU6zyK2NQdIg4HHgQ8ASUn3wERHxaMk8ZwIbRsQXJW2ezb9lRKzutiy3MZhZ35RXHB03ECuO\n",
       "GrGNYSqwICKejIhVwFXAQd3meZaukdlGAi91TwpmZn0mHccA6Qk1D3nexzCWlKk7LQbe022ei4Hb\n",
       "JT0DjABm9rQwny2YWR/8Bt+X0G95JoZqduRfAu6PiGmS3gncJmnXiFirX6TsslOn9ohor02YZtZy\n",
       "Ih4pOoQiSJoGTFvf5eSZGJYAbSXP20hnDaXeS+rnnIh4QtJCYCJwb/eFRcSZ+YRpZk1NUivenNYf\n",
       "2QFze+dzSV/rz3LybGO4F5ggabxSXySHATd0m+cxUuM0krYkJYU/5xiTmbWKroqjc4sOpdXkdsYQ\n",
       "EaslnUhqABoEXBIRj0r6TDb9IuDfgUslPUBKUv8SEcvyisnMWkT3iiOrqabpEqM/JVdm1mIq9YTa\n",
       "DDuxgvR33+neVc2smXwJ2B1XHOXKZwxm1jzSGcMqnyVUx2cMZtb6It4sOoSBwJ3omVnjSRVHWxcd\n",
       "xkDlxGBmjaVr7OX/V3QoA5UTg5k1hvKeUM8FTis4ogHLbQxmVjyPvdxQXJVkZsWTZgLD8H0JNdXy\n",
       "Yz47MZiZ9U0jjsdgZmZNyInBzOonjb18eNFhWO+cGMwsf+UVR97vNDhXJZlZvlxx1HScuc0sP9Kx\n",
       "eOzlpuOqJDPLj7Qt8LoTQjFcrmpmZmVcrmpmxZJ88NYinBjMbP10VRxdXHQoVhuuSjKz/vPYyy3J\n",
       "Zwxm1ndr94TqiqMW4jMGM+uPk/DYyy3LVUlm1nfSYOAt94Ta2Dzms5nVT8TqokOw/LiNwcx6ltoS\n",
       "JhQdhtWXE4OZVdY19vKpRYdi9eXEYGbl0lnC10kVR/8BnFBwRFZnbmMwsy7pLOEy4ClccTRguSrJ\n",
       "zLpI+wObAz91xVHzcyd6ZmZWxp3omZlZTTgxmA1E0m5Inyo6DGtMTgxmA0lXxdHNwMqiw7HG5Kok\n",
       "s4FC2o3UE6orjqxXPmMwGwikI0lnCecAM5wUrDeuSjIbCKS3AzghDCwNWZUkabqkxyTNl3RGD/NM\n",
       "k/QnSQ9Jas8zHrMBK+IZJwWrVm5nDJIGAY8DHwKWkPpcOSIiHi2ZZ1Pgt8CHI2KxpM0jYmmFZfmM\n",
       "waxa0gZEdBQdhhWvEc8YpgILIuLJiFgFXAUc1G2ejwPXRsRigEpJwcyq1FVxNLvoUKy55ZkYxpLG\n",
       "ge20OHut1ARgtKRfS7pX0tE5xmPWulLF0b3AbsA/FxyNNbk8y1WruUY1hPRF3hfYCLhL0u8jYn6O\n",
       "cZm1Dmko8GXgeOB04Ar3cWTrK8/EsARoK3neRjprKLUIWBoRK4GVku4AdgXWSgySzix52h4R7TWN\n",
       "1qw5fRKPvWwZSdOAaeu9nBwbnweTGp/3BZ4B7mbtxuftgR8AHwY2BP4AHBYRj3RblhufzSqRNgDC\n",
       "ZwlWScON+RwRqyWdSBrsYxBwSUQ8Kukz2fSLIuIxSTcDc4EO4OLuScHMeuHqI8uBb3AzawapLWEC\n",
       "EQ8XHYo1j0YsVzWzWpAmky7FutrI6sKJwaxRpfsSzgJuBb4LuJtsqwv3rmrWiKRdgMtJlXyuOLK6\n",
       "chuDWSOS9gLege9LsPXgMZ/NzKyMG5/NzKwmemxjkPQqPXdrERExMp+QzAaQVHE0jYjvFx2KWace\n",
       "zxgiYnhEjOjh4aRgtj7KK45eKjocs1K9nTGM7u2NEbGs9uGYDQDpLOEnuOLIGlRv5ar30XsPqe+o\n",
       "cSxmrU/6GHAh7gnVGpirkszqSdoM2NBnCVYPuZarShpFGlRnWOdrEXFHX1fWX04MZmZ9l1vvqpI+\n",
       "DZxMGk/hT8CewF3APn1dmdmAIg0i4q2iwzDrq2ruYziFNH7zkxGxNzAFeDnXqMyaWVfF0Q1Fh2LW\n",
       "H9UkhtezEdaQNCwiHgMm5huWWZPq6gl1d+DTBUdj1i/VdKK3KGtjuB64TdJy4MlcozJrNh572VpI\n",
       "n6qSsvFERwI3R8SbeQVVYb1ufLbGJh0JHAEc54ojaxS5VSVJ2hN4JCJeyZ6PBHaIiD/0K9J+cGKw\n",
       "hiel76fPEqyB5JkY7gd2i2xsWUmDgHsjYkq/Iu0HJwYzs77LtXfVKBlwPFL53aC+rsisJaSKo92K\n",
       "DsMsT9UkhoWSTpY0RNJQSacAf847MLOG47GXbYCoJjF8FngfsITU6deewHF5BmXWUNYee/nogiMy\n",
       "y5X7SjLrjTQJuIJ0UOSKI2squbUxSJoo6VeSHs6e7yLpX/sTpFkTGkQ6S/iIk4INFNVUJd0BfB74\n",
       "YURMUSrLeygidqpHgFkMPmMwM+ujPKuSNiq9ZyFSJlnV1xWZmVlzqCYxvChpu84nkv4BeDa/kMwK\n",
       "IE1G+krRYZg1gmoSw4nARcBESc8Ap5L6gzFrfuUVR08VHY5ZI1hnJ3oR8QSwr6ThgIBXgZm4Iz1r\n",
       "dh572ayiHs8YJA2XdJqkCyR9DlgBfAh4GDiyXgGa5UL6e7ruS3DFkVmJHquSJF0HvEIarW0/0ghu\n",
       "rwMnR8T9dYsQVyVZDqQRwAgnBGtlNe9ET9LciNgl+3sQqcF5m85Be+rJicHMrO/yKFddM1Zt1nHe\n",
       "kiKSgtl6k4YUHYJZM+ntjOEtUrtCp7cBnYkhImJkzrGVxuIzBuu7rlHVpgHTPFaCDTT93Xf2WJUU\n",
       "Ee5a25pXecXREU4KZtWrajwGs6axdk+orjgy66NcE4Ok6ZIekzRf0hm9zPduSaslfTTPeGxA+DCw\n",
       "O+m+hMt9pmDWd7l1u51VMj1OuvdhCXAPcEREPFphvttI7RmXRsS1FZblNgarjsdeNlsj16E9+2kq\n",
       "sCAinoyIVcBVwEEV5jsJ+BnwYo6x2EAREU4KZusnz8QwFlhU8nxx9toaksaSksWF2Uv+QVt1UlvC\n",
       "e4sOw6wV5ZkYqtnJfx/4QtaVt7KHWe+6xl4+dc2lIzOrmXV2orcelpC60ejURjprKLU7cFX2294c\n",
       "2F/Sqoi4ofvCJJ1Z8rQ9ItprGq01vq77Eo4HTgeu8GUjsy6SppHu21m/5eTY+DyY1Pi8L/AM6Qhv\n",
       "rcbnkvkvBf5/RFxXYZobnwc6aUdgNh572axqNb/BbX1FxGpJJwK3kMbNvSQiHpX0mWz6RXmt21rS\n",
       "m6T7EnyWYJaz3M4YaslnDGZmfdeI5apmZtaEnBissaSxl89xtZFZcZwYrDGU93H0YNHhmA1keZar\n",
       "mlXHYy+bNRSfMVixpH1xT6hmDcVVSVYsaUNgMycEs9qr+ZjPjcSJwcys71yuao1PGlZ0CGa2bk4M\n",
       "lr+uiqPfuAzVrPE5MVi+unpC3R2Y4e4szBqfE4Plw2MvmzUt38dgeflbYDd8X4JZ03FVkplZi3JV\n",
       "kpmZ1YQTg62f1Jawb9FhmFntODFY/3VVHJ2I5O+SWYvwj9n6bu2Ko48S0VFwVGZWI65Ksr6Rtgeu\n",
       "wj2hmrUsVyVZ30hvB/YFfuqb1cwamzvRMzOzMi5XNTOzmnBisMrS2Ms/dLWR2cDjH72VK684+h3Q\n",
       "+NcazaymXJVkXTz2spnhMwbrJL0X94RqZrgqyTpJg4C/IeK5okMxs9pwuaqZmZVxuapVT9q46BDM\n",
       "rHE5MQwkXRVHd2eXjszM1uLEMFCUj738d0S8VXBEZtagnBhancdeNrM+8n0MrW8SMBnfl2BmVXJV\n",
       "kplZi3JVkpmZ1YQTQ6tIbQkHFh2GmTU/J4ZW0FVxdByS243MbL3knhgkTZf0mKT5ks6oMP1ISQ9I\n",
       "mivpt5J2yTumlrF2xdFBRKwuOCoza3K5Hl0q3UT1A+BDwBLgHkk3RMSjJbP9GfhARLwsaTrwI2DP\n",
       "PONqCdJ2wM9wT6hmVmN5nzFMBRZExJMRsYo0iPxBpTNExF0R8XL29A/AuJxjahUvAd/B9yWYWY3l\n",
       "nRjGAotKni/OXuvJPwE35RpRq4hYTsRsmqHe2MyaSt4NlVXvtCTtDXwSeF8P088sedoeEe3rFZmZ\n",
       "WYuRNA2Ytr7LyTsxLAHaSp63kc4aymQNzhcD0yNieaUFRcSZeQTY8FLF0enAJ0iX48zMKsoOmNs7\n",
       "n0v6Wn+Wk/elpHuBCZLGSxoKHAbcUDqDpK2B64CjImJBzvE0j/KKo1sBVxuZWV3kesYQEaslnQjc\n",
       "AgwCLomIRyV9Jpt+EfBVYBRwoSSAVRExNc+4Gp7HXjazArmvpEYjTSEl0tOBK9y4bGb95aE9W0U6\n",
       "bdqciBeLDsXMmpsTg5mZlXHvqs1I2qToEMzMunNiKEJXxdF9pGotM7OG4cRQb6lx+R7S2Mt7EfFm\n",
       "wRGZmZVxYqiXrrOEW4D/wH0cmVmDct/99fNOYGd8X4KZNThXJZmZtShXJZmZWU04MdRaaks4tOgw\n",
       "zMz6y4mhlroqjo5B2rDocMzM+sONz7WQ7kX4MnA8cBrwU/dxZM1Ekr+vTa6W7bBODOtLegdwPfA0\n",
       "rjiyJuZjmeaV9Uxdu+U1w5ehoauSpI2BA4Gr/cuyZpX9xooOw/pJUsUzBneiZ2b95sTQ3GqdGNz4\n",
       "bGZmZZwYqiVNQboOaVjRoZiZ5cmJYV3K+zj6OfBGwRGZmeXKiaE3Xfcl7EaqOPJQm2YFmTZtGqNH\n",
       "j+bNN99c6/VLLrmk7LX29nba2trWPI8IZs2axaRJkxg+fDhtbW3MnDmThx56qKYxLlu2jEMOOYTh\n",
       "w4czfvx45syZ0+O8b7zxBqeeeipjx45l9OjRnHDCCaxevXrN9EcffZR99tmHTTfdlAkTJnD99dfX\n",
       "NNbeODH0RJpIV0+oM1yGalacJ598krvvvpstttiCG264oWyapHWWa55yyinMmjWL888/n+XLlzNv\n",
       "3jwOPvhgbrzxxprGecIJJzBs2DBeeOEFrrzySo4//ngeeeSRivOeffbZ3HfffTz88MPMmzeP++67\n",
       "j2984xsArF69moMOOogZM2awfPlyfvSjH3HUUUcxf/78msbbo4ho+EcKs4B1w6iiP7sfftTjkf3G\n",
       "GtZZZ50VH/nIR+Ib3/hGHHjggWXTpk2bFpdccknZa7/+9a9j3LhxERExb968GDRoUNxzzz25xvjq\n",
       "q6/G0KFDY/78+WteO+aYY+ILX/hCxfn32GOPuOaaa9Y8nz17drS1tUVExIMPPhjDhw8vm3+//faL\n",
       "r3zlKxWX1dM+sr/7Tp8x9CZiedEhmBlcfvnlHHbYYcycOZNbbrmFF154oer3/upXv6KtrY099tij\n",
       "6vd87nOfY9SoURUfkydPrvieefPmMXjwYLbbbrs1r+266648/PDDPa4n23kD0NHRweLFi/nrX/9a\n",
       "cd6Ojo6aX/rqiRMDgLRZ0SGYNTKpNo/++M1vfsOSJUuYMWMGEyZMYMcdd2T27NlVv/+ll15iq622\n",
       "6tM6L7jgApYvX17xcf/991d8z6uvvsrIkSPLXhsxYkSPO/rp06dz3nnnsXTpUp577jlmzZqFJFas\n",
       "WMHEiRPZYostOOecc1i1ahW33nord9xxBytXruzT5+ivgZ0YuiqO/oS0UdHhmDWqiNo8+uOyyy5j\n",
       "v/32Y8SIEQAceuihXHbZZWumDx48mFWrVpW9Z9WqVQwZMgSAzTbbjGeffbZ/K++D4cOH88orr5S9\n",
       "9vLLL6+Ju7svf/nLTJkyhcmTJ/P+97+fQw45hMGDB7PlllsyZMgQrr/+em688UbGjBnD9773PWbO\n",
       "nMm4ceNy/xwwkBNDecXRnkSsKDgiM+tm5cqVXH311dx+++2MGTOGMWPGcO655/LAAw8wd+5cALbe\n",
       "emsWLlxY9r6FCxcyfvx4APbdd18WL17MH//4x6rX+9nPfpYRI0ZUfEyaNKnie971rnexevVqFixY\n",
       "sOa1Bx54gJ133rni/MOGDeP8889n8eLFLFiwgNGjR5dd7po0aRLt7e0sXbqUX/ziFzzxxBNMnTq1\n",
       "6s+wXvrTMFHvB7VsfIahAWcFvBBwdGTdgvjhx0B+0KCNz7Nnz47Ro0fHokWL4vnnn4/nn38+nnvu\n",
       "ufjABz4Qp512WkRE3HLLLbHFFlvE3XffHR0dHfH444/HDjvsEBdddNGa5Zx00kkxYcKEaG9vjzfe\n",
       "eCNWrlwZc+bMibPPPrum8R5++OFxxBFHxGuvvRZ33nlnbLLJJvHII49UnHfJkiWxZMmS6OjoiLvu\n",
       "uiva2tritttuWzN97ty5sXLlynjttdfinHPOiW233TbefPPNisvqaR/Z331n4V/IqoKsbWLYJuC/\n",
       "A95e9Ofyw49GeTRqYpg+fXqcfvrpa71+9dVXx5gxY+Ktt96KiIgf//jHsdNOO8XIkSNju+22i29/\n",
       "+9vR0dHIvesDAAAG0klEQVRR9p7zzjsvdtppp9hoo41i7Nixcfjhh/e40+6vZcuWxcEHHxwbb7xx\n",
       "bLPNNjFnzpw105566qkYPnx4LFq0KCIi7rjjjhg/fnxstNFGsf3228fs2bPLlvX5z38+Ro0aFcOH\n",
       "D48DDjggnnjiiR7XW+vE4E70zMyd6DU5d6JnZma5at3EkCqO/rHmI1iYmbW41kwMXRVH/wC4DNXM\n",
       "rA9aKzGU94Ta2cfRawVHZWbWVFpnzGdpHHAjHnvZzGy9tE5VkjSUNPbyz2mGD2XWQFyV1Nw85rOZ\n",
       "1Zykxt8RWK9qmRhyvZQkaTrwfWAQ8F8R8e0K88wC9gdWAMdGxJ/yjMnM1uYDLyuVW+OzpEHAD4Dp\n",
       "wI7AEZJ26DbPAcB2ETEBOA64sIoFT0H6BdLIdc7bgiRNKzqGRuFt0cXboou3xfrLsyppKrAgIp6M\n",
       "iFXAVcBB3eaZAVwGEBF/ADaVtGXFpZVXHM0GKvdl2/qmFR1AA5lWdAANZFrRATSQaUUH0OzyvJQ0\n",
       "FlhU8nwx8J4q5hkHPF9heffgiiMzs9zlmRiqbczqfm2zp/edC1zhiiMzs3zlVpUkaU/gzIiYnj3/\n",
       "ItBR2gAt6YdAe0RclT1/DPhgRDzfbVlOBmZm/dBoVUn3AhMkjQeeAQ4Djug2zw3AicBVWSL5S/ek\n",
       "AK6YMDOrp9wSQ0SslnQiqbF4EHBJRDwq6TPZ9Isi4iZJB0haALwGfCKveMzMrDpNcYObmZnVT0N1\n",
       "oidpuqTHJM2XdEYP88zKpj+g1ItqS1rXtpB0ZLYN5kr6raRdioizHqr5XmTzvVvSakkfrWd89VLl\n",
       "72OapD9JekhSe51DrJsqfh+bS7pZ0v3Ztji2gDDrQtKPJT0v6cFe5unbfrM/w77l8SBdbloAjAeG\n",
       "APcDO3Sb5wDgpuzv9wC/LzruArfF3wKbZH9PH8jbomS+24H/BT5WdNwFfSc2BR4GxmXPNy867gK3\n",
       "xZnAtzq3A/ASMLjo2HPaHnsBU4AHe5je5/1mI50x1PaGuOa2zm0REXdFxMvZ0z+Q7v9oRdV8LwBO\n",
       "An4GvFjP4Oqomu3wceDaiFgMEBFL6xxjvVSzLZ4FOntHGAm8FBGr6xhj3UTEncDyXmbp836zkRJD\n",
       "pZvdxlYxTyvuEKvZFqX+Cbgp14iKs85tIWksacfQ2aVKKzacVfOdmACMlvRrSfdKOrpu0dVXNdvi\n",
       "YmAnSc8ADwCn1Cm2RtTn/WYjjcdQ6xvimlnVn0nS3sAngfflF06hqtkW3we+EBGhNJRrK5Y3V7Md\n",
       "hgC7AfuSRi68S9LvI2J+rpHVXzXb4kvA/RExTdI7gdsk7RoRA7UrnT7tNxspMSwB2kqet5EyW2/z\n",
       "jMteazXVbAuyBueLgekR0dupZDOrZlvsTroXBtL15P0lrYqIG+oTYl1Usx0WAUsjYiWwUtIdwK5A\n",
       "qyWGarbFe4FvAkTEE5IWAhNJ91cNNH3ebzbSpaQ1N8QpDbpzGOkGuFI3AMfAmjurK94Q1wLWuS0k\n",
       "bQ1cBxwVEQsKiLFe1rktImLbiHhHRLyD1M5wfIslBaju9/E/wPslDZK0Eamh8ZE6x1kP1WyLx4AP\n",
       "AWTX0ycCf65rlI2jz/vNhjljCN8Qt0Y12wL4KjAKuDA7Ul4VEVOLijkvVW6Lllfl7+MxSTcDc4EO\n",
       "4OKIaLnEUOV34t+BSyU9QDoA/peIWFZY0DmSNAf4ILC5pEXA10iXFfu93/QNbmZmVqaRLiWZmVkD\n",
       "cGIwM7MyTgxmZlbGicHMzMo4MZiZWRknBjMzK+PEYAOWpLeyLqo7H1v3Mu+r2b/je+veuI/r30ZS\n",
       "91ENzQrXMDe4mRVgRURUO6ZHHjf8vIPUI+qcHJZt1m8+YzDLSNpY0i8l/TEbAGlGH98/XtLt2WAo\n",
       "v5TUlr3+E0kfK5mvsyO3s4G9srOVgdz7pzUYJwYbyN5WchnpWuB14JCI2B3YBzi3j8s7H7g0InYF\n",
       "rgRmZa/3dLZxBnBnREyJiPP6Eb9ZLnwpyQaylaWXkiQNAb4laS9SX0Nvl7RFRLxQ5fL2BA7O/v4p\n",
       "8J11zN+K3YNbC3BiMOtyJKnb7t0i4q2sq+ZhPc0s6VJgMrAkIg7sfLnCrKvJzs4lbQAMrWnUZjXm\n",
       "S0lmXUYCL2RJYW9gm95mjohPZJeBOpPC74DDs7+PBO7I/n6SNGYEpGEWh2R//xUYUaPYzWrGicEG\n",
       "su7X/q8E9pA0FzgaeLSHeXtqMzgJ+ETW1fORdA0neTHwQUn3ky43vZq9/gDwlqT73fhsjcTdbpuZ\n",
       "WRmfMZiZWRknBjMzK+PEYGZmZZwYzMysjBODmZmVcWIwM7MyTgxmZlbGicHMzMr8H097btWEOh2H\n",
       "AAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1059da190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 1 0]\n",
      "[ 0.03919853  0.0401668   0.03758962 ...,  0.05738717  0.89730153\n",
      "  0.04664608]\n",
      "[ 0.          0.          0.         ...,  0.99834711  0.99917355  1.        ]\n",
      "[ 0.00546448  0.01092896  0.01639344 ...,  1.          1.          1.        ]\n",
      "[ 0.97599692  0.97542541  0.96781251 ...,  0.00508785  0.00473233\n",
      "  0.00411287]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "df = pd.read_csv('data/SMSSpamCollection', delimiter='\\t', header=None)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1], df[0])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "lb = LabelBinarizer()\n",
    "y_train2 = np.array([number[0] for number in lb.fit_transform(y_train)])\n",
    "y_test2 = np.array([number[0] for number in lb.fit_transform(y_test)])\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train2)\n",
    "predictions = classifier.predict_proba(X_test)\n",
    "false_positive_rate, recall, thresholds = roc_curve(y_test2, predictions[:, 1])\n",
    "roc_auc = auc(false_positive_rate, recall)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, recall, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Fall-out')\n",
    "plt.show()\n",
    "\n",
    "print(y_test2)\n",
    "print(predictions[:,1])\n",
    "print(false_positive_rate)\n",
    "print(recall)\n",
    "print(thresholds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DT Conclusion\n",
    "  - 의미상 더 포괄적인 ML metric들이 있으나 다른 ML metrics를 완전히 대신할 수는 없다.\n",
    "  - 용도에 맞는 metric(accuracy, precision, recall, f-measure, ROC, AUC 등)을 1개 혹은 여러개 선택하여 사용한다.\n",
    "  - 혹은, 실제 가치를 이들 metric의 function으로 정의하여 사용한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tuning models with grid search\n",
    "- Hyperparameters are parameters of the model that are not learned\n",
    "- Hyperparameters of the logistic regression SMS classifier\n",
    "  - the value of the regularization term\n",
    "  - thresholds used to remove words that appear too frequently or infrequently\n",
    "  - In scikit-learn, hyperparameters are set through the model's constructor\n",
    "- Grid search\n",
    "  - a common method to select the hyperparameter values that produce the best model.\n",
    "  - an exhaustive search that trains and evaluates a model for each possible combination of the hyperparameter values supplied by the developer\n",
    "  - Computationally costly for even small sets of hyperparameter values\n",
    "  - embarrassingly parallel problem\n",
    "- GridSearchCV() function in scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 274 out of 288 | elapsed:   14.3s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 288 out of 288 | elapsed:   14.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.966\n",
      "Best parameters set:\n",
      "\tclf__penalty: 'l2'\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__max_features: 2500\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: None\n",
      "Accuracy: 0.977027997128\n",
      "Precision: 1.0\n",
      "Recall: 0.835051546392\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "parameters = {\n",
    "    'vect__max_df': (0.25, 0.5, 0.75),\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__max_features': (2500, 5000, 10000, None),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "#   'vect__use_idf': (True, False),\n",
    "#   'vect__norm': ('l1', 'l2'),\n",
    "    'clf__penalty': ('l1', 'l2'),\n",
    "#    'clf__C': (0.01, 0.1, 1, 10),\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=3)\n",
    "df = pd.read_csv('data/SMSSpamCollection', delimiter='\\t', header=None)\n",
    "X, y, = df[1], df[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "lb = LabelBinarizer()\n",
    "y_train2 = np.array([number[0] for number in lb.fit_transform(y_train)])\n",
    "y_test2 = np.array([number[0] for number in lb.fit_transform(y_test)])\n",
    "grid_search.fit(X_train, y_train2)\n",
    "print 'Best score: %0.3f' % grid_search.best_score_\n",
    "print 'Best parameters set:'\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print '\\t%s: %r' % (param_name, best_parameters[param_name])\n",
    "predictions = grid_search.predict(X_test)\n",
    "print 'Accuracy:', accuracy_score(y_test2, predictions)\n",
    "print 'Precision:', precision_score(y_test2, predictions)\n",
    "print 'Recall:', recall_score(y_test2, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class classification\n",
    "- scikit-learn uses a strategy called\n",
    "  - one-vs.-all\n",
    "      - uses one binary classifier for each of the possible classes\n",
    "      - The class that is predicted with the greatest confidence is assigned to the instance.\n",
    "      - LogisticRegression supports multi-class classification using the one-versus-all strategy out of the box.\n",
    "  - one-vs.-the-rest\n",
    "\n",
    "#### Example) classify the sentiments of phrases taken from movie reviews in the Rotten Tomatoes data set\n",
    "- Data Download: http://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhraseId      156060\n",
      "SentenceId    156060\n",
      "Phrase        156060\n",
      "Sentiment     156060\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('movie-reviews/train.tsv', header=0, delimiter='\\t')\n",
    "print df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PhraseId  SentenceId                                             Phrase  \\\n",
      "0         1           1  A series of escapades demonstrating the adage ...   \n",
      "1         2           1  A series of escapades demonstrating the adage ...   \n",
      "2         3           1                                           A series   \n",
      "3         4           1                                                  A   \n",
      "4         5           1                                             series   \n",
      "\n",
      "   Sentiment  \n",
      "0          1  \n",
      "1          2  \n",
      "2          2  \n",
      "3          2  \n",
      "4          2  \n"
     ]
    }
   ],
   "source": [
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Sentiment column contains the response variables.\n",
    "  - 0: the sentiment negative\n",
    "  - 1: somewhat negative\n",
    "  - and so on. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    A series of escapades demonstrating the adage ...\n",
      "1    A series of escapades demonstrating the adage ...\n",
      "2                                             A series\n",
      "3                                                    A\n",
      "4                                               series\n",
      "5    of escapades demonstrating the adage that what...\n",
      "6                                                   of\n",
      "7    escapades demonstrating the adage that what is...\n",
      "8                                            escapades\n",
      "9    demonstrating the adage that what is good for ...\n",
      "Name: Phrase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df['Phrase'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    156060.000000\n",
      "mean          2.063578\n",
      "std           0.893832\n",
      "min           0.000000\n",
      "25%           2.000000\n",
      "50%           2.000000\n",
      "75%           3.000000\n",
      "max           4.000000\n",
      "Name: Sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print df['Sentiment'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    79582\n",
      "3    32927\n",
      "1    27273\n",
      "4     9206\n",
      "0     7072\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    0.509945\n",
      "3    0.210989\n",
      "1    0.174760\n",
      "4    0.058990\n",
      "0    0.045316\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print df['Sentiment'].value_counts()/df['Sentiment'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   1 jobs       | elapsed:    2.2s\n",
      "[Parallel(n_jobs=3)]: Done  50 jobs       | elapsed:   51.0s\n",
      "[Parallel(n_jobs=3)]: Done  68 out of  72 | elapsed:  1.3min remaining:    4.8s\n",
      "[Parallel(n_jobs=3)]: Done  72 out of  72 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.624\n",
      "Best parameters set:\n",
      "\tclf__C: 10\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__use_idf: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "parameters = {\n",
    "    'vect__max_df': (0.25, 0.5),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__use_idf': (True, False),\n",
    "    'clf__C': (0.1, 1, 10),\n",
    "}\n",
    "df = pd.read_csv('movie-reviews/train.tsv', header=0, delimiter='\\t')\n",
    "X, y = df['Phrase'], df['Sentiment'].as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=3, verbose=1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print 'Best score: %0.3f' % grid_search.best_score_\n",
    "print 'Best parameters set:'\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print '\\t%s: %r' % (param_name, best_parameters[param_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification performance metrics\n",
    "- confusion matrices\n",
    "- Accuracy Precision, recall, and F1 score can be computed for each of the classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.639305395361\n",
      "Confusion Matrix: [[ 1134  1693   676    55     2]\n",
      " [  907  6020  6019   558    20]\n",
      " [  223  3147 32775  3545   173]\n",
      " [   30   419  6350  8267  1373]\n",
      " [    4    35   464  2452  1689]]\n",
      "Classification Report:              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.32      0.39      3560\n",
      "          1       0.53      0.45      0.48     13524\n",
      "          2       0.71      0.82      0.76     39863\n",
      "          3       0.56      0.50      0.53     16439\n",
      "          4       0.52      0.36      0.43      4644\n",
      "\n",
      "avg / total       0.62      0.64      0.63     78030\n",
      "\n",
      "[1 2 2 ..., 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "predictions = grid_search.predict(X_test)\n",
    "print 'Accuracy:', accuracy_score(y_test, predictions)\n",
    "print 'Confusion Matrix:', confusion_matrix(y_test, predictions)\n",
    "print 'Classification Report:', classification_report(y_test, predictions)\n",
    "print df['Sentiment'].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label classification and problem transformation\n",
    "- two groups of approaches for multi-label classification.\n",
    "![](multi-label.png)\n",
    "\n",
    "#### Problem transformation methods\n",
    "- cast the original multi-label problem as a set of single-label classification problems\n",
    "\n",
    "#### The first problem transformation method\n",
    "- The multi-label classification problem that had five classes is now a multi-class classification problem with seven classes\n",
    "![](multi-label-first.png)\n",
    "\n",
    "#### The seond problem transformation method\n",
    "- Train one binary classifier for each of the labels in the training set\n",
    "- Each classifier predicts whether or not the instance belongs to one label.\n",
    "![](multi-label-second.png)\n",
    "## Multi-label classification performance metrics\n",
    "- Hamming loss\n",
    "  - average fraction of incorrect labels\n",
    "  -  perfect score is zero\n",
    "  - accuracy와 유사함\n",
    "\n",
    "- Jaccard similarity (or the Jaccard index)\n",
    "  - size of the intersection of the predicted labels and the true labels divided by the size of the union of the predicted and true labels.\n",
    "  - It ranges from zero to one\n",
    "  - one is the perfect score.\n",
    "  - precision과 recall을 합한 후 일반화한 형태\n",
    "\n",
    "$$J(Predicted, True) = \\frac{|Predicted \\cap True | }{|Predicted \\cup True|}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import hamming_loss\n",
    "print hamming_loss(np.array([[0.0, 1.0], [1.0, 1.0]]),\n",
    "np.array([[0.0, 1.0], [1.0, 1.0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "print hamming_loss(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [1.0, 1.0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print hamming_loss(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [0.0, 1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333333333333\n"
     ]
    }
   ],
   "source": [
    "print hamming_loss(np.array([[0.0, 1.0, 1.0], [1.0, 1.0, 1.0]]), np.array([[1.0, 1.0, 1.0], [0.0, 1.0, 1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score \n",
    "print jaccard_similarity_score(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[0.0, 1.0], [1.0, 1.0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print jaccard_similarity_score(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [1.0, 1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print jaccard_similarity_score(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [0.0, 1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667\n"
     ]
    }
   ],
   "source": [
    "print jaccard_similarity_score(np.array([[0.0, 1.0, 1.0], [1.0, 1.0, 1.0]]), np.array([[1.0, 1.0, 1.0], [0.0, 1.0, 1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
