{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8 Optimization for TrainingDeep Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 손고리즘 / 손고리즘ML 파트 2 - DeepLearning [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 8.1 Optimization for Model Training\n",
    "* 8.2 Challenges in Optimization\n",
    "* 8.3 Optimization Algorithms I: Basic Algorithms\n",
    "* 8.4 Optimization Algorithms II: Adaptive LearningRates\n",
    "* 8.5 Optimization Algorithms III: Approximate Second-Order Methods\n",
    "* 8.6 Optimization Algorithms IV: Natural Gradient Meth-ods\n",
    "* 8.7 Optimization Strategies and Meta-Algorithms\n",
    "* 8.8 Hints, Global Optimization and Curriculum Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.1.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.1 Optimization for Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 8.1.1 Empirical Risk Minimization\n",
    "* 8.1.2 Surrogate Loss Functions\n",
    "* 8.1.3 Batch and Minibatch Algorithms\n",
    "* 8.1.4 Generalization and Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.1 Empirical Risk Minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.2.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.2 Surrogate Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.3 Batch and Minibatch Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.3.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.4.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.5.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minibatch sizes are generally driven by the following factors :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Larger batches provide a more accurate estimate of the gradient, but withless than linear returns.\n",
    "* Multicore architectures are usually underutilized by extremely small batches.This motivates using some absolute minimum batch size, below which thereis no reduction in the time to process a minibatch.\n",
    "* If all examples in the batch are to be processed in parallel (as is typicallythe case), then the amount of memory scales with the batch size. For manyhardware setups this is the limiting factor in batch size\n",
    "* Some kinds of hardware achieve better runtime with speciﬁc sizes of arrays.Especially when using GPU, it is common for power of 2 batch sizes to oﬀerbetter runtime. Typical power of 2 batch sizes range from 32 to 256, with16 sometimes being attempted for large models.\n",
    "* Small batches can oﬀer a regularizing eﬀect. Generalization error is oftenbest for a batch size of 1, though this might take a very long time to trainand require a small learning rate to maintain stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diﬀerent kinds of algorithms use diﬀerent kinds of information in diﬀerentways, and some are more sensitive to sampling error than others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many optimization problems in machine learning decompose over exampleswell enough that we can compute entire separate updates over diﬀerent examplesin parallel. In other words, we can compute the update that minimizes J(x) for one minibatch of examples x at the same time that we compute the update forseveral other minibatches. This is discussed further in Chapter 12.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.4 Generalization and Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, typically we minimize a objective function deﬁned as anexpectation of some per-example loss across the training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.6.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we would usually prefer to minimize the corresponding objective func-tion where the expectation is taken across the data generating distribution ratherthan just the ﬁnite training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.7.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, we care about generalization error, not training error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, we use an optimization algorithm based on minibatch estimates ofthe gradient. During the ﬁrst stages of learning, this is equivalent to minimizingthe generalization error directly. After we have used up the training data andbegin to repeat minibatches, the two criteria are diﬀerent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main way in which optimization for machine learning is actuallydiﬀerent from traditional optimization, rather than just a special case of opti-mization. Many neural network optimization algorithms are implicitly designedin ways that are intended to yield better results in terms of generalization error,even if they perform worse as an optimization algorithm (yield worse trainingerror or minimize the training error more slowly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2 Challenges in Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 8.2.1 Local Minima\n",
    "* 8.2.2 Ill-Conditioning\n",
    "* 8.2.3 Plateaus, Saddle Points, and Other Flat Regions\n",
    "* 8.2.4 Cliﬀs and Exploding Gradients\n",
    "* 8.2.5 Vanishing and Exploding Gradients - An Introduction tothe Issue of Learning Long-Term Dependencie\n",
    "* 8.2.6 Inexact Gradients\n",
    "* 8.2.7 Theoretical Limits of Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.1 Local Minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap4.1.png\" />\n",
    "<img src=\"figures/cap4.2.png\" />\n",
    "<img src=\"figures/cap4.3.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.2 Ill-Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning refers to how rapidly a function changes with respect to small changes in in its input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.3 Plateaus, Saddle Points, and Other Flat Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretical work has shown that saddle points (and the ﬂat regions surround-ing them) are important barriers to training neural networks, and may be moreimportant than local minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that change rapidly when their inputs are perturbed slightly can be pproblematic for scientific computaition because rounding errors in the inputs can result in large change in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap4.4.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.4 Cliﬀs and Exploding Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas the issues of ill-conditioning and saddle points discussed in the previoussections arise because of the second-order structure of the objective function (asa function of the parameters), neural networks involve stronger non-linearitieswhich do not ﬁt well with this picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second-order methods and momentum or gradient-averaging methods in-troduced in Section 8.5 are able to reduce the diﬃculty due to ill-conditioning byincreasing the size of the steps in the low-curvature directions (the “valley”, inFigure 8.1) and decreasing the size of the steps in the high-curvature directions(the steep sides of the valley, in the ﬁgure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.8.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, although classical second order methods can help, as shown in Fig-ure 8.2, due to higher order derivatives, the objective function may have a lotmore non-linearity, which often does not have the nice symmetrical shapes thatthe second-order “valley” picture builds in our mind. Instead, there are cliﬀswhere the gradient rises sharply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the parameters approach a cliﬀ region,the gradient update step can move the learner towards a very bad conﬁguration,ruining much of the progress made during recent training iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.9.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As illustrated in Figure 8.3, the cliﬀ can be dangerous whether we approach itfrom above or from below, but fortunately there are some fairly straightforwardheuristics that allow one to avoid its most serious consequences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic ideais to limit the size of the jumps that one would make. Indeed, one should keepin mind that when we use the gradient to make an update of the parameters, weare relying on the assumption of inﬁnitesimal moves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing that is guaranteed is that a small enough stepin that direction will be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient clipping heuristics are described in more detail in Section 10.8.7.The basic idea is to bound the magnitude of the update step, i.e., not trust thegradient too much when it is very large in magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.10.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.5 Vanishing and Exploding Gradients - An Introduction tothe Issue of Learning Long-Term Dependencie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exploding or Vanishing Product of Jacobians\n",
    "* Consequence for Recurrent Networks: Diﬃculty of Learning Long-Term Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploding or Vanishing Product of Jacobians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.11.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.12.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.13.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consequence for Recurrent Networks: Diﬃculty of Learning Long-Term Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.14.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.15.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.16.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.17.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.6 Inexact Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.7 Theoretical Limits of Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.3 Optimization Algorithms I: Basic Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 8.3.1 Gradient Descent\n",
    "* 8.3.2 Stochastic Gradient Descent\n",
    "* 8.3.3 Online Gradient Descent Minimizes Generalization Error\n",
    "* 8.3.4 Momentum\n",
    "* 8.3.5 Nesterov Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3.1 Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.18.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3.2 Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.19.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.20.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.21.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3.3 Online Gradient Descent Minimizes Generalization Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.22.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.23.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.24.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3.4 Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.25.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.26.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.27.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.28.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3.5 Nesterov Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.29.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.30.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.31.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.4 Optimization Algorithms II: Adaptive LearningRates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 8.4.1 AdaGrad\n",
    "* 8.4.2 RMSprop\n",
    "* 8.4.3 Adam\n",
    "* 8.4.4 AdaDelta\n",
    "* 8.4.5 Choosing the Right Optimization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4.1 AdaGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.32.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4.2 RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.33.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4.3 Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.34.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4.4 AdaDelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.35.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.36.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4.5 Choosing the Right Optimization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.37.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.5 Optimization Algorithms III: Approximate Second-Order Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 8.5.1 Newton’s Method\n",
    "* 8.5.2 Conjugate Gradients\n",
    "* 8.5.3 BFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5.1 Newton’s Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.38.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.39.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.40.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5.2 Conjugate Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.41.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5.3 BFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.42.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.6 Optimization Algorithms IV: Natural Gradient Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.7 Optimization Strategies and Meta-Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 8.7.1 Batch Normalization\n",
    "* 8.7.2 Coordinate Descent\n",
    "* 8.7.3 Initialization Strategies\n",
    "* 8.7.4 Greedy Supervised Pre-training\n",
    "* 8.7.5 Designing Models to Aid Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.1 Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.2 Coordinate Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.3 Initialization Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.43.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.44.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.4 Greedy Supervised Pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.5 Designing Models to Aid Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.8 Hints, Global Optimization and Curriculum Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.45.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1] bengio's book - Chapter 8 Optimization for TrainingDeep Models - http://www.iro.umontreal.ca/~bengioy/dlbook/version-07-08-2015/optimization.html\n",
    "* [2] Optimization, higher-level representations, image features - http://vision.stanford.edu/teaching/cs231n/slides/lecture4.pdf\n",
    "* [3] Getting Neural Networks to work: cross-validation process, optimization, debugging - http://vision.stanford.edu/teaching/cs231n/slides/lecture6.pdf\n",
    "* [4] Loss functions for classification - https://en.wikipedia.org/wiki/Loss_functions_for_classification\n",
    "* [5] Surrogate Loss Functions in Machine Learning - http://fa.bianp.net/blog/2014/surrogate-loss-functions-in-machine-learning/\n",
    "* [6] Condition number - https://en.wikipedia.org/wiki/Condition_number"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
