{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Chapter 9 Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 손고리즘 / 손고리즘 ML : 파트 3 - DML [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 9.1 The Convolution Operation\n",
    "* 9.2 Motivation\n",
    "* 9.3 Pooling\n",
    "* 9.4 Convolution and Pooling as an Inﬁnitely Strong Prior\n",
    "* 9.5 Variants of the Basic Convolution Function\n",
    "* 9.6 Structured Outputs\n",
    "* 9.7 Convolutional Modules\n",
    "* 9.8 Data Types\n",
    "* 9.9 Eﬃcient Convolution Algorithms\n",
    "* 9.10 Random or Unsupervised Features\n",
    "* 9.11 The Neuroscientiﬁc Basis for Convolutional Networks\n",
    "* 9.12 Convolutional Networks and the History of DeepLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional networks (also known as convolutional neural networks or CNNs)are a specialized kind of neural network for processing data that has a known,grid-like topology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name “convolutional neural network”indicates that the network employs a mathematical operation called convolution. Convolution is a specialized kind of linear operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional networksare simply neural networks that use convolution in place of general matrix multiplication in at least one of their layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.1 The Convolution Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Suppose we are tracking the location of a spaceship with a laser sensor. Ourlaser sensor provides a single output x(t), the position of the spaceship at timet. \n",
    "* Now suppose that our laser sensor is somewhat noisy. To obtain a less noisyes timate of the spaceship’s position, we would like to average together several measurements. \n",
    "* Of course, more recent measurements are more relevant, so wewill want this to be a weighted average that gives more weight to recent measurements.\n",
    "* We can do this with a weighting function w(a), where a is the age of ameasurement. If we apply such a weighted average operation at every moment,we obtain a new function s providing a smoothed estimate of the position of thespaceship:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution operation is typically denoted with an asterisk:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.2.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input & kernel & feature map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In convolutional network terminology, the ﬁrst argument (in this example,the function x) to the convolution is often referred to as the input and the secondargument (in this example, the function w) as the kernel. The output is sometimes referred to as the feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### discrete convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.3.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multidimensional case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning applications, the input is usually a multidimensional arrayof data and the kernel is usually a multidimensional array of learn-able parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will refer to these multidimensional arrays as tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we use a two-dimensional image I as our input, we probably alsowant to use a two-dimensional kernel K :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.4.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that convolution is commutative, meaning we can equivalently write:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.5.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the commutative property is useful for writing proofs, it is not usuallyan important property of a neural network implementation. Instead, many neuralnetwork libraries implement a related function called the cross-correlation, whichis the same as convolution but without ﬂipping the kernel:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.6.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Many machine learning libraries implement cross-correlation but call it convolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete convolution can be viewed as multiplication by a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing convolution as matrix multiplication usually does nothelp to implement convolution operations, but it is useful for understanding anddesigning neural networks.\n",
    "* Any neural network algorithm that works with matrix multiplication and does not depend on speciﬁc properties of the matrix structure should work with convolution, without requiring any further changes to the neuralnetwork. \n",
    "* Typical convolutional neural networks do make use of further specializations in order to deal with large inputs eﬃciently, but these are not strictly necessary from a theoretical perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.2 Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution leverages three important ideas that can help improve a machinelearning system: \n",
    "* sparse interactions, \n",
    "* parameter sharing, and \n",
    "* equivariant representations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.12.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.3 Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical layer of a convolutional network consists of three stages (see Fig. 9.7).\n",
    "* In the ﬁrst stage, the layer performs several convolutions in parallel to produce aset of presynaptic activations. \n",
    "* In the second stage, each presynaptic activation isrun through a nonlinear activation function, such as the rectiﬁed linear activationfunction. This stage is sometimes called the detector stage. \n",
    "* In the third stage,we use a pooling function to modify the output of the layer further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pooling function \n",
    "* replaces the output of the net at a certain location with asummary statistic of the nearby outputs. \n",
    "* For example, \n",
    "    - the max pooling operation \n",
    "        - reports the maximum output within a rectangular neighborhood. \n",
    "* Other popular pooling functions include \n",
    "    - the average of a rectangular neighborhood, \n",
    "    - the L2 norm of a rectangular neighborhood, or \n",
    "    - a weighted average based on the distance from the central pixe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.13.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### translation invariant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all cases, pooling helps to make the representation become invariant to small translations of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEY IDEA : Invariance to local translationcan be a very useful property if we care more about whether somefeature is present than exactly where it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.15.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inﬁnitely strong prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of pooling can be viewed as adding an inﬁnitely strong prior thatthe function the layer learns must be invariant to small translations. When thisassumption is correct, it can greatly improve the statistical eﬃciency of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transformation invariant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling over spatial regions produces invariance to translation, but if we pool over the outputs of separately parametrized convolutions, the features can learn which transformations to become invariant to (see Fig. 9.9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.16.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pooling with downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.17.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.4 Convolution and Pooling as an Inﬁnitely Strong Prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* An inﬁnitely strong prior places zero probability on some parameters and says that these parameter values are completely forbidden, regardless of how much support the data gives to those values.\n",
    "* Of course, implementing a convolutional net as a fully connected net with aninﬁnitely strong prior would be extremely computationally wasteful. But thinkingof a convolutional net as a fully connected net with an inﬁnitely strong prior cangive us some insights into how convolutional nets work.\n",
    "* One key insight is that convolution and pooling can cause underﬁtting.\n",
    "    - If a task relies on preserving precisionspatial information, then using pooling on all features can cause underﬁtting.\n",
    "* Another key insight from this view is that we should only compare convolutional models to other convolutional models in benchmarks of statistical learningperformance.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.5 Variants of the Basic Convolution Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.18.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.19.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.20.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.21.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.22.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.23.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.24.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.25.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.26.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.6 Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.7 Convolutional Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.8 Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.27.png\" width=600 />\n",
    "<img src=\"figures/cap9.28.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 9.1: Examples of diﬀerent formats of data that can be used with convolutional networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.9 Eﬃcient Convolution Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.10 Random or Unsupervised Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.11 The Neuroscientiﬁc Basis for Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.29.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.30.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.31.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.12 Convolutional Networks and the History of DeepLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.32.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* [1] bengio's book - Chapter 9 Convolutional Networks - http://www.iro.umontreal.ca/~bengioy/dlbook/version-07-08-2015/convnets.html\n",
    "* [2] Linear Systems and Convolution - http://www.slideshare.net/lineking/lecture4-26782530\n",
    "* [3] Convolutional Neural Networks: architectures, convolution / pooling layers - http://vision.stanford.edu/teaching/cs231n/slides/lecture7.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
